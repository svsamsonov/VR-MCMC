{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.polynomial as P\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import ZVnbrosse\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from potentials import GaussPotential,GaussMixture,GausMixtureIdent,GausMixtureSame,BananaShape\n",
    "from samplers import MCMC_sampler,Generate_train,ULA_light\n",
    "from baselines import set_function,construct_ESVM_kernel,GenerateSigma\n",
    "from martingale import approx_q\n",
    "from optimize import Run_eval_test,optimize_parallel_new \n",
    "from utils import * \n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(k, x):\n",
    "    if k==0:\n",
    "        return 1.0\n",
    "    if k ==1:\n",
    "        return x\n",
    "    if k==2:\n",
    "        return (x**2 - 1)/np.sqrt(2)\n",
    "    c = np.zeros(k+1,dtype = float)\n",
    "    c[k] = 1.0\n",
    "    h = P.hermite_e.hermeval(x,c) / np.sqrt(sp.special.factorial(k)) \n",
    "    return h\n",
    "\n",
    "def compute_H(k,x):\n",
    "    return H(k[0],x[:,0])*H(k[1],x[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_traj(coefs_poly_regr,gamma,r_seed,lag,d,cov,N_test,x0):\n",
    "    \"\"\"\n",
    "    function to perform 1-dimensional martingale decomposition\n",
    "    \"\"\"\n",
    "    X_test,Noise = generate_traj(x0,N_test,gamma,r_seed,d,cov)\n",
    "    test_stat_vanilla = np.zeros(N_test,dtype = float)\n",
    "    test_stat_vr = np.zeros_like(test_stat_vanilla)\n",
    "    #compute number of basis polynomials\n",
    "    basis_funcs = np.array([[1,0],[0,1],[1,1],[2,0],[0,2]])\n",
    "    num_basis_funcs = len(basis_funcs)\n",
    "    #compute polynomials of noise variables Z_l\n",
    "    poly_vals = np.zeros((num_basis_funcs,N_test), dtype = float)\n",
    "    for k in range(len(basis_funcs)):\n",
    "        poly_vals[k,:] = compute_H(basis_funcs[k],Noise)\n",
    "    #initialize function\n",
    "    f_vals_vanilla = np.sum(np.sin(X_test),axis=1)\n",
    "    #array to store control variates values\n",
    "    cvfs = np.zeros_like(f_vals_vanilla)\n",
    "    #compute coeffitients bar_a\n",
    "    bar_a_0_1 = np.zeros((lag,N_test),dtype=float)\n",
    "    bar_a_1_0 = np.zeros_like(bar_a_0_1)\n",
    "    bar_a_1_1 = np.zeros_like(bar_a_0_1)\n",
    "    bar_a_2_0 = np.zeros_like(bar_a_0_1)\n",
    "    bar_a_0_2 = np.zeros_like(bar_a_0_1)\n",
    "    for i in range(lag):\n",
    "        #coefficients with H_0_1\n",
    "        bar_a_0_1[i,1:] = coefs_poly_regr[i,1]*cov[0,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,0]+\\\n",
    "                        coefs_poly_regr[i,2]*cov[1,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,1]+\\\n",
    "                        2*coefs_poly_regr[i,3]*cov[0,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,0]*(X_test[:-1]+gamma*b(X_test[:-1]))[:,0]+\\\n",
    "                        coefs_poly_regr[i,4]*(((X_test[:-1]+gamma*b(X_test[:-1]))[:,0])*sigma(X_test[:-1])[:,1]*np.sqrt(gamma)*cov[1,1] +\\\n",
    "                                             ((X_test[:-1]+gamma*b(X_test[:-1]))[:,1])*sigma(X_test[:-1])[:,0]*np.sqrt(gamma)*cov[0,1])+\\\n",
    "                        2*coefs_poly_regr[i,5]*cov[1,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,1]*(X_test[:-1]+gamma*b(X_test[:-1]))[:,1]\n",
    "        bar_a_0_1[i,0] = coefs_poly_regr[i,1]*cov[0,1]*np.sqrt(gamma)*sigma(x0)[0]+\\\n",
    "                        coefs_poly_regr[i,2]*cov[1,1]*np.sqrt(gamma)*sigma(x0)[1]+\\\n",
    "                        2*coefs_poly_regr[i,3]*cov[0,1]*np.sqrt(gamma)*sigma(x0)[0]*(x0+gamma*b(x0))[0]+\\\n",
    "                        coefs_poly_regr[i,4]*(((x0+gamma*b(x0))[0])*sigma(x0)[1]*np.sqrt(gamma)*cov[1,1] +\\\n",
    "                                             ((x0+gamma*b(x0))[1])*sigma(x0)[0]*np.sqrt(gamma)*cov[0,1])+\\\n",
    "                        2*coefs_poly_regr[i,5]*cov[1,1]*np.sqrt(gamma)*sigma(x0)[1]*(x0+gamma*b(x0))[1]\n",
    "        #coefficients with H_1_0\n",
    "        bar_a_1_0[i,1:] = coefs_poly_regr[i,1]*cov[0,0]*np.sqrt(gamma)*sigma(X_test[:-1])[:,0]+\\\n",
    "                        coefs_poly_regr[i,2]*cov[0,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,1]+\\\n",
    "                        2*coefs_poly_regr[i,3]*cov[0,0]*np.sqrt(gamma)*sigma(X_test[:-1])[:,0]*(X_test[:-1]+gamma*b(X_test[:-1]))[:,0]+\\\n",
    "                        coefs_poly_regr[i,4]*(((X_test[:-1]+gamma*b(X_test[:-1]))[:,0])*sigma(X_test[:-1])[:,1]*np.sqrt(gamma)*cov[0,1] +\\\n",
    "                                             ((X_test[:-1]+gamma*b(X_test[:-1]))[:,1])*sigma(X_test[:-1])[:,0]*np.sqrt(gamma)*cov[0,0])+\\\n",
    "                        2*coefs_poly_regr[i,5]*cov[0,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,1]*(X_test[:-1]+gamma*b(X_test[:-1]))[:,1]\n",
    "        bar_a_1_0[i,0] = coefs_poly_regr[i,1]*cov[0,0]*np.sqrt(gamma)*sigma(x0)[0]+\\\n",
    "                        coefs_poly_regr[i,2]*cov[0,1]*np.sqrt(gamma)*sigma(x0)[1]+\\\n",
    "                        2*coefs_poly_regr[i,3]*cov[0,0]*np.sqrt(gamma)*sigma(x0)[0]*(x0+gamma*b(x0))[0]+\\\n",
    "                        coefs_poly_regr[i,4]*(((x0+gamma*b(x0))[0])*sigma(x0)[1]*np.sqrt(gamma)*cov[0,1] +\\\n",
    "                                             ((x0+gamma*b(x0))[1])*sigma(x0)[0]*np.sqrt(gamma)*cov[0,0]) +\\\n",
    "                        2*coefs_poly_regr[i,5]*cov[0,1]*np.sqrt(gamma)*sigma(x0)[1]*(x0+gamma*b(x0))[1]\n",
    "        #second-order coefficients\n",
    "        bar_a_1_1[i,1:] = coefs_poly_regr[i,4]*gamma#+\\\n",
    "                        #2*coefs_poly_regr[i,7]*gamma*(X_test[:-1]+gamma*b(X_test[:-1]))[:,0] +\\\n",
    "                        #*coefs_poly_regr[i,8]*gamma*(X_test[:-1]+gamma*b(X_test[:-1]))[:,1] \n",
    "        bar_a_1_1[i,0] = coefs_poly_regr[i,4]*gamma#+\\\n",
    "                        #2*coefs_poly_regr[i,7]*gamma*(x0+gamma*b(x0))[0] +\\\n",
    "                        #2*coefs_poly_regr[i,8]*gamma*(x0+gamma*b(x0))[1] \n",
    "        #coefficients with H_2_0\n",
    "        bar_a_2_0[i,1:] = np.sqrt(2)*coefs_poly_regr[i,3]*gamma #+\\\n",
    "                        #3*np.sqrt(2)*coefs_poly_regr[i,6]*gamma*(X_test[:-1]+gamma*b(X_test[:-1]))[:,0] +\\\n",
    "                        #np.sqrt(2)*coefs_poly_regr[i,7]*gamma*(X_test[:-1]+gamma*b(X_test[:-1]))[:,1]\n",
    "        bar_a_2_0[i,0] = np.sqrt(2)*coefs_poly_regr[i,3]*gamma #+\\\n",
    "                        #3*np.sqrt(2)*coefs_poly_regr[i,6]*gamma*(x0+gamma*b(x0))[0] +\\\n",
    "                        #np.sqrt(2)*coefs_poly_regr[i,7]*gamma*(x0+gamma*b(x0))[1]\n",
    "        #coefficients with H_0_2\n",
    "        bar_a_0_2[i,1:] = np.sqrt(2)*coefs_poly_regr[i,5]*gamma #+\\\n",
    "                        #3*np.sqrt(2)*coefs_poly_regr[i,9]*gamma*(X_test[:-1]+gamma*b(X_test[:-1]))[:,0] +\\\n",
    "                        #np.sqrt(2)*coefs_poly_regr[i,8]*gamma*(X_test[:-1]+gamma*b(X_test[:-1]))[:,1]\n",
    "        bar_a_0_2[i,0] = np.sqrt(2)*coefs_poly_regr[i,5]*gamma #+\\\n",
    "                        #3*np.sqrt(2)*coefs_poly_regr[i,9]*gamma*(x0+gamma*b(x0))[0] +\\\n",
    "                        #np.sqrt(2)*coefs_poly_regr[i,8]*gamma*(x0+gamma*b(x0))[1]\n",
    "    bar_a_1_0 = bar_a_1_0*poly_vals[0,:]\n",
    "    bar_a_0_1 = bar_a_0_1*poly_vals[1,:]\n",
    "    bar_a_1_1 = bar_a_1_1*poly_vals[2,:]\n",
    "    bar_a_2_0 = bar_a_2_0*poly_vals[3,:]\n",
    "    bar_a_0_2 = bar_a_0_2*poly_vals[4,:]\n",
    "    #compute martingale sums\n",
    "    M_n_0_1 = 0.0\n",
    "    M_n_1_0 = 0.0\n",
    "    M_n_1_1 = 0.0\n",
    "    M_n_2_0 = 0.0\n",
    "    M_n_0_2 = 0.0\n",
    "    for l in range(N_test):\n",
    "        for r in range(min(N_test-l,lag)):\n",
    "            M_n_0_1 += bar_a_0_1[r,l]\n",
    "            M_n_1_0 += bar_a_1_0[r,l]\n",
    "            M_n_1_1 += bar_a_1_1[r,l]\n",
    "            M_n_2_0 += bar_a_2_0[r,l]\n",
    "            M_n_0_2 += bar_a_0_2[r,l]\n",
    "    return np.mean(f_vals_vanilla), np.mean(f_vals_vanilla)-(M_n_0_1 + M_n_1_0)/N_test, np.mean(f_vals_vanilla)-(M_n_0_1 + M_n_1_0 + M_n_1_1 + M_n_2_0 + M_n_0_2)/N_test\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_q_enhanced(X_train,Y_train,N_traj_train,lag,max_deg):\n",
    "    \"\"\"\n",
    "    Function to regress q functions on a polynomial basis;\n",
    "    Args:\n",
    "        X_train - train tralectory;\n",
    "        Y_train - function values;\n",
    "        N_traj_train - number of training trajectories;\n",
    "        lag - truncation point for coefficients, those for |p-l| > lag are set to 0;\n",
    "        max_deg - maximum degree of polynomial in regression\n",
    "    \"\"\"\n",
    "    dim = X_train[0,:].shape[0]\n",
    "    #print(\"dimension = \",dim)\n",
    "    coefs_poly = np.array([])\n",
    "    for i in range(lag):\n",
    "        x_all = np.array([])\n",
    "        y_all = np.array([])\n",
    "        for j in range(N_traj_train):\n",
    "            y = Y_train[j,i:,0]\n",
    "            if i == 0:\n",
    "                x = X_train[j,:]\n",
    "            else:\n",
    "                x = X_train[j,:-i]\n",
    "            #concatenate results\n",
    "            if x_all.size == 0:\n",
    "                x_all = x\n",
    "            else:\n",
    "                x_all = np.concatenate((x_all,x),axis = 0)\n",
    "            y_all = np.concatenate([y_all,y])\n",
    "        #should use polyfeatures here\n",
    "        #print(\"variance: \",np.var(y_all))\n",
    "        #print(y_all[:50])\n",
    "        poly = PolynomialFeatures(max_deg)\n",
    "        X_features = poly.fit_transform(x_all)\n",
    "        sin_features = np.sin(X_features)\n",
    "        cos_features = np.cos(X_features)\n",
    "        All_features = np.concatenate((X_features,sin_features,cos_features),axis=1)\n",
    "        print(All_features.shape)\n",
    "        #print(X_features.shape)\n",
    "        lstsq_results = np.linalg.lstsq(All_features,y_all,rcond = None)\n",
    "        coefs = copy.deepcopy(lstsq_results[0])\n",
    "        coefs.resize((1,All_features.shape[1]))           \n",
    "        if coefs_poly.size == 0:\n",
    "            coefs_poly = copy.deepcopy(coefs)\n",
    "        else:\n",
    "            coefs_poly = np.concatenate((coefs_poly,coefs),axis=0)\n",
    "    return coefs_poly\n",
    "\n",
    "def approx_q_poly(X_train,Y_train,N_traj_train,lag,max_deg):\n",
    "    \"\"\"\n",
    "    Function to regress q functions on a polynomial basis;\n",
    "    Args:\n",
    "        X_train - train tralectory;\n",
    "        Y_train - function values;\n",
    "        N_traj_train - number of training trajectories;\n",
    "        lag - truncation point for coefficients, those for |p-l| > lag are set to 0;\n",
    "        max_deg - maximum degree of polynomial in regression\n",
    "    \"\"\"\n",
    "    dim = X_train[0,:].shape[0]\n",
    "    #print(\"dimension = \",dim)\n",
    "    coefs_poly = np.array([])\n",
    "    for i in range(lag):\n",
    "        x_all = np.zeros((X_train.shape[0]*(X_train.shape[1]-i),X_train.shape[2]))\n",
    "        y_all = np.zeros((X_train.shape[0]*(X_train.shape[1]-i),1))\n",
    "        print(x_all.shape)\n",
    "        #x_all = np.array([])\n",
    "        #y_all = np.array([])\n",
    "        for j in range(N_traj_train):\n",
    "            if i > 0:\n",
    "                x_all[j*(X_train.shape[1]-i):(j+1)*(X_train.shape[1]-i)] = X_train[j,:-i]\n",
    "                y_all[j*(X_train.shape[1]-i):(j+1)*(X_train.shape[1]-i)] = Y_train[j,i:]\n",
    "            elif i ==0:\n",
    "                x_all[j*(X_train.shape[1]-i):(j+1)*(X_train.shape[1]-i)] = X_train[j,:]\n",
    "                y_all[j*(X_train.shape[1]-i):(j+1)*(X_train.shape[1]-i)] = Y_train[j,i:]\n",
    "        #should use polyfeatures here\n",
    "        #print(\"variance: \",np.var(y_all))\n",
    "        #print(y_all[:50])\n",
    "        poly = PolynomialFeatures(max_deg)\n",
    "        X_features = poly.fit_transform(x_all)\n",
    "        #print(X_features.shape)\n",
    "        lstsq_results = np.linalg.lstsq(X_features,y_all,rcond = None)\n",
    "        coefs = copy.deepcopy(lstsq_results[0])\n",
    "        coefs.resize((1,X_features.shape[1]))           \n",
    "        if coefs_poly.size == 0:\n",
    "            coefs_poly = copy.deepcopy(coefs)\n",
    "        else:\n",
    "            coefs_poly = np.concatenate((coefs_poly,coefs),axis=0)\n",
    "    return coefs_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0.2\n",
    "sig = 1.0\n",
    "cov = np.array([[1,0.0],[0.0,1]])\n",
    "\n",
    "def b(X_t):\n",
    "    \"\"\"\n",
    "    b function in the diffusion\n",
    "    \"\"\"\n",
    "    #return a*(c-X_t)\n",
    "    if len(X_t.shape) == 1:\n",
    "        return -np.array([X_t[0] + a*np.sin(X_t[1]),X_t[1] + a*np.sin(X_t[0])])\n",
    "    else:\n",
    "        return -np.transpose(np.array([X_t[:,0] + a*np.sin(X_t[:,1]),X_t[:,1] + a*np.sin(X_t[:,0])]))\n",
    "\n",
    "def sigma(X_t):\n",
    "    \"\"\"\n",
    "    b function in the diffusion\n",
    "    \"\"\"\n",
    "    return sig*np.ones_like(X_t)\n",
    "\n",
    "def sample_discretized_diffusion(X_t,gamma_t,d,cov):\n",
    "    \"\"\"\n",
    "    args:   X_t - current value, \n",
    "            gamma_t - step size;\n",
    "            d - dimension;\n",
    "            cov - covariance matrix\n",
    "    returns:  (X_{t+1},xi_{t+1}) - value at the next time moment and the corresponding noise variable\n",
    "    \"\"\"\n",
    "    xi = np.random.randn(d)\n",
    "    return X_t + gamma_t*b(X_t) + np.sqrt(gamma_t)*sigma(X_t)*(cov @ xi),xi\n",
    "\n",
    "#currently we use this function without the burn-in\n",
    "def generate_traj(x0,n,gamma,r_seed,d,cov):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        x0 - starting point;\n",
    "        n - number of steps;\n",
    "        gamma - step size (assumed to be fixed for now);\n",
    "    returns:\n",
    "        x_all,noise_all - np.arrays of shape (n,)  \n",
    "    \"\"\"\n",
    "    x_all = np.zeros((n,d),dtype = float)\n",
    "    noise_all = np.zeros((n,d),dtype = float)\n",
    "    np.random.seed(r_seed)\n",
    "    x_all[0],noise_all[0] = sample_discretized_diffusion(x0,gamma,d,cov)\n",
    "    for i in range(1,n):\n",
    "        x_all[i],noise_all[i] = sample_discretized_diffusion(x_all[i-1],gamma,d,cov)\n",
    "    return x_all,noise_all\n",
    "\n",
    "def run_monte_carlo(x,f_type):\n",
    "    if f_type == \"quadratic\":\n",
    "        f_vals = x**2\n",
    "    else:\n",
    "        raise \"not implemented error\"\n",
    "    return np.mean(f_vals,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4*10**3 #sample size\n",
    "gamma = 1e-1 # Step size\n",
    "n_traj = 100\n",
    "d = 2\n",
    "n_traj_test = 100 # Number of independent MCMC trajectories for test\n",
    "f_type = \"linear\"\n",
    "K_max = 2 #max degree of Hermite polynomial\n",
    "S_max = 2 #max degree of polynomial during regression stage\n",
    "lag = 100 #maximal lag order\n",
    "N_test = 1*10**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample discretized diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_observations(x0,n,gamma,r_seed,d,cov,n_traj):\n",
    "    X_train_all = np.zeros((n_traj,n,d),dtype=float)\n",
    "    Noise_train_all = np.zeros_like(X_train_all)\n",
    "    Y_train_all = np.zeros((n_traj,n,1),dtype=float)\n",
    "    nbcores = multiprocessing.cpu_count()\n",
    "    trav = Pool(nbcores)\n",
    "    train_traj = trav.starmap(generate_traj, [(x0,n,gamma,r_seed+i,d,cov) for i in range (n_traj)])\n",
    "    #res = trav.starmap(test_traj, [(Cur_pot,coefs_poly,step,test_seed+i,lag,K_max,S_max,N_burn,N_test,d,f_type,inds_arr,params,x0,fixed_start) for i in range (n_traj_test)])\n",
    "    trav.close()\n",
    "    train_traj = np.asarray(train_traj)\n",
    "    #print(train_traj.shape)\n",
    "    X_train_all = train_traj[:,0,:,:]\n",
    "    Noise_train_all = train_traj[:,1,:,:]\n",
    "    Y_train_all[:,:,0] = np.sum(np.sin(X_train_all),axis=2)\n",
    "    #for i in range(n_traj):\n",
    "        #X_train, noise_train = generate_traj(x0,n,gamma,r_seed+i,d,cov)\n",
    "        #set target function\n",
    "        #Y_train = np.sum(np.sin(X_train),axis=1)\n",
    "        #X_train_all[i] = X_train\n",
    "        #Y_train_all[i,:,0] = Y_train\n",
    "        #Noise_train_all[i] = noise_train\n",
    "        #X_train = X_train.reshape((1,-1,d))\n",
    "        #Y_train = Y_train.reshape((1,-1,1))\n",
    "    return X_train_all, Noise_train_all, Y_train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 1*np.array([0.0,0.0],dtype = float)\n",
    "r_seed = 1812\n",
    "N_gammas = 5\n",
    "X_train = np.zeros((N_gammas,n_traj,n,2),dtype=float)\n",
    "Noise_train = np.zeros((N_gammas,n_traj,n,2),dtype=float)\n",
    "Y_train = np.zeros((N_gammas,n_traj,n,1),dtype=float)\n",
    "\n",
    "for i in range(N_gammas):\n",
    "    X_train[i],Noise_train[i],Y_train[i] = generate_observations(x0,n,(i+1)*gamma,r_seed,d,cov,n_traj)\n",
    "    \n",
    "#X_train, noise_train, Y_train = generate_observations(x0,n,gamma,r_seed,d,cov,n_traj)\n",
    "#X_train_1, noise_train_1, Y_train_1 = generate_observations(x0,n,2*gamma,r_seed,d,cov,n_traj)\n",
    "#X_train_2, noise_train_2, Y_train_2 = generate_observations(x0,n,3*gamma,r_seed,d,cov,n_traj)\n",
    "#X_train_3, noise_train_3, Y_train_3 = generate_observations(x0,n,4*gamma,r_seed,d,cov,n_traj)\n",
    "#X_train_4, noise_train_4, Y_train_4 = generate_observations(x0,n,5*gamma,r_seed,d,cov,n_traj)\n",
    "#X_train_5, noise_train_5, Y_train_5 = generate_observations(x0,n,10*gamma,r_seed,d,cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli:: Optimize coefficients by solving regression with polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "coefs_poly = trav.starmap(approx_q_poly, [(X_train[i],Y_train[i],n_traj,lag,S_max) for i in range (N_gammas)])\n",
    "#res = trav.starmap(test_traj, [(Cur_pot,coefs_poly,step,test_seed+i,lag,K_max,S_max,N_burn,N_test,d,f_type,inds_arr,params,x0,fixed_start) for i in range (n_traj_test)])\n",
    "trav.close()\n",
    "coefs_poly = np.asarray(coefs_poly)\n",
    "print(coefs_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "regr_vals_enh = np.zeros((lag,X_train[0].shape[1]),dtype=float)\n",
    "regr_vals_poly = np.zeros((lag,X_train[0].shape[1]),dtype=float)\n",
    "features = np.zeros((X_train[0].shape[1],6),dtype=float)\n",
    "features[:,0] = 1.0\n",
    "features[:,1:3] = X_train[0,0,:,:]\n",
    "features[:,3] = X_train[0,0,:,0]**2 \n",
    "features[:,4] = X_train[0,0,:,0]*X_train[0,0,:,1]\n",
    "features[:,5] = X_train[0,0,:,1]**2\n",
    "sin_features = np.sin(features)\n",
    "cos_features = np.cos(features)\n",
    "All_features = np.concatenate((features,sin_features,cos_features),axis=1)\n",
    "\n",
    "features[:,6] = X_train_1[0,:,0]**3\n",
    "features[:,7] = (X_train_1[0,:,0]**2)*X_train_1[0,:,1]\n",
    "features[:,8] = (X_train_1[0,:,0])*(X_train_1[0,:,1]**2)\n",
    "features[:,9] = X_train_1[0,:,1]**3\n",
    "features[:,10] = X_train_1[0,:,0]**4\n",
    "features[:,11] = (X_train_1[0,:,0]**3)*(X_train_1[0,:,1])\n",
    "features[:,12] = (X_train_1[0,:,0]**2)*(X_train_1[0,:,1]**2)\n",
    "features[:,13] = (X_train_1[0,:,0])*(X_train_1[0,:,1]**3)\n",
    "features[:,14] = X_train_1[0,:,1]**4\n",
    "\n",
    "for i in range(len(regr_vals_poly)):\n",
    "    #regr_vals_enh[i,:] = np.sum(coefs_enhanced_0[i,:]*All_features,axis=1)\n",
    "    regr_vals_poly[i,:] = np.sum(coefs_poly[0,i,:]*features,axis=1)\n",
    "    #regr_vals_2nd[i,:] = np.sum(coefs_poly_2nd[i,:]*features[:,:10],axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "err_poly = np.zeros(lag)\n",
    "err_enhanced = np.zeros_like(err_poly)\n",
    "for i in range(lag):\n",
    "    err_enhanced[i] = np.mean((Y_train_1[0,i:,0]-regr_vals_enh[i,:len(Y_train[0,i:,0])])**2)\n",
    "    err_poly[i] = np.mean((Y_train_1[0,i:,0]-regr_vals_poly[i,:len(Y_train[0,i:,0])])**2)\n",
    "print(np.sum(err_poly))\n",
    "#print(np.sum(err_enhanced))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cur_lag = 2\n",
    "N_pts = 500\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Testing regression model\",fontsize=20)\n",
    "plt.plot(Y_train[0,cur_lag:N_pts+cur_lag,0],color='r',label='true function')\n",
    "plt.plot(regr_vals[cur_lag,:N_pts],color='g',label = 'practical approximation')\n",
    "plt.legend(loc = 'upper left',fontsize = 16)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test = 5*10**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seed = 1453\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res_0 = trav.starmap(test_traj, [(coefs_poly[0],gamma,test_seed+i,lag,d,cov,N_test,x0) for i in range (n_traj_test)])\n",
    "#res = trav.starmap(test_traj, [(Cur_pot,coefs_poly,step,test_seed+i,lag,K_max,S_max,N_burn,N_test,d,f_type,inds_arr,params,x0,fixed_start) for i in range (n_traj_test)])\n",
    "trav.close()\n",
    "res_new_0 = np.asarray(res_0)\n",
    "print(res_new_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seed = 1453\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res = trav.starmap(test_traj, [(coefs_poly[1],2*gamma,test_seed+i,lag//2,d,cov,N_test,x0) for i in range (n_traj_test)])\n",
    "#res = trav.starmap(test_traj, [(Cur_pot,coefs_poly,step,test_seed+i,lag,K_max,S_max,N_burn,N_test,d,f_type,inds_arr,params,x0,fixed_start) for i in range (n_traj_test)])\n",
    "trav.close()\n",
    "res_new = np.asarray(res)\n",
    "print(res_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seed = 1453\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res_1 = trav.starmap(test_traj, [(coefs_poly[2],3*gamma,test_seed+i,lag//3,d,cov,N_test,x0) for i in range (n_traj_test)])\n",
    "#res = trav.starmap(test_traj, [(Cur_pot,coefs_poly,step,test_seed+i,lag,K_max,S_max,N_burn,N_test,d,f_type,inds_arr,params,x0,fixed_start) for i in range (n_traj_test)])\n",
    "trav.close()\n",
    "res_new_1 = np.asarray(res_1)\n",
    "print(res_new_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seed = 1453\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res_2 = trav.starmap(test_traj, [(coefs_poly[3],4*gamma,test_seed+i,lag//4,d,cov,N_test,x0) for i in range (n_traj_test)])\n",
    "#res = trav.starmap(test_traj, [(Cur_pot,coefs_poly,step,test_seed+i,lag,K_max,S_max,N_burn,N_test,d,f_type,inds_arr,params,x0,fixed_start) for i in range (n_traj_test)])\n",
    "trav.close()\n",
    "res_new_2 = np.asarray(res_2)\n",
    "print(res_new_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seed = 1453\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res_3 = trav.starmap(test_traj, [(coefs_poly[4],5*gamma,test_seed+i,lag//5,d,cov,N_test,x0) for i in range (n_traj_test)])\n",
    "#res = trav.starmap(test_traj, [(Cur_pot,coefs_poly,step,test_seed+i,lag,K_max,S_max,N_burn,N_test,d,f_type,inds_arr,params,x0,fixed_start) for i in range (n_traj_test)])\n",
    "trav.close()\n",
    "res_new_3 = np.asarray(res_3)\n",
    "print(res_new_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\n",
    "#labels = ['Vanilla\\n Euler scheme', 'Euler scheme \\nwith MDCV-1']\n",
    "labels = ['Vanilla\\n Euler scheme', 'Euler scheme \\nwith MDCV-1','Euler scheme \\nwith MDCV-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [res_new_0[:,0],res_new_0[:,1]]#, res_new_0[:,2]] \n",
    "boxplot_ind(data, title, labels,path=\"./2d_nonsymmetric_potential_linear_lag_20.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_axis_style_boxplot(ax, labels, parts):\n",
    "    colors = (sns.color_palette(\"muted\")[0:7])\n",
    "    ax.grid(color='black', linestyle='-', linewidth=0.15, alpha=0.6)    \n",
    "    ax.set_xticks(np.arange(1, len(labels)+1))\n",
    "    ax.set_xticklabels(labels, fontsize=12)\n",
    "    ax.set_xlim(0.5, len(labels) + 0.5)\n",
    "    #ax.set_ylim(-0.12, 0.12)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    \n",
    "    for pc,i in zip(parts['boxes'],range(len(labels))):\n",
    "        pc.set(facecolor=colors[i],alpha=0.65)\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_linewidth(0.65)\n",
    "    \n",
    "\n",
    "def boxplot_ind(data, title, labels, path):\n",
    "    meanprops = dict(linestyle='-', linewidth=1, color='black')\n",
    "    medianprops = dict(linestyle='', linewidth=0)\n",
    "\n",
    "    fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(8, 4), sharey=True, frameon=False,dpi=100)      \n",
    "    fig.suptitle(title, fontsize=20)\n",
    "    parts = ax1.boxplot(data,  widths=0.6, patch_artist=True, meanline=True, showmeans=True, medianprops=medianprops,meanprops = meanprops, showfliers=False)\n",
    "    set_axis_style_boxplot(ax1, labels, parts)\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "    plt.savefig(path)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\n",
    "#labels = ['Vanilla\\n Euler scheme', 'Euler scheme \\nwith MDCV-1']\n",
    "labels = ['MDCV-2, \\n $\\\\gamma = 0.1$', 'MDCV-2, \\n $\\\\gamma = 0.2$',\\\n",
    "          'MDCV-2, \\n $\\\\gamma = 0.3$', 'MDCV-2, \\n $\\\\gamma = 0.4$', 'MDCV-2, \\n $\\\\gamma = 0.5$']#,\\\n",
    "          #'MDCV-2, \\n $\\\\gamma = 0.2$']\n",
    "#labels = ['lag \\n = 10','lag \\n = 20', 'lag \\n = 30', 'lag \\n = 40', 'lag \\n = 50', 'lag \\n = 60']\n",
    "#labels = ['lag = 30', 'lag = 40', 'lag = 50', 'lag = 60']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [res_new_0[:,0],res_new[:,0],res_new_1[:,0], res_new_2[:,0],res_new_3[:,0]]#,res_new_4[:,1]] \n",
    "#data = [res_new_1[:,2], res_new_2[:,2],res_new_3[:,2],res_new_4[:,2]] \n",
    "boxplot_ind(data, title, labels,path=\"./2d_nonsymmetric_potential_gamma_1st_order__influence_upd.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(N_test*np.var(res_new_0[:,0]),N_test*np.var(res_new[:,0]),N_test*np.var(res_new_1[:,0]),N_test*np.var(res_new_2[:,0]),N_test*np.var(res_new_3[:,0]))#,N_test*np.var(res_new_4[:,2]))\n",
    "print(N_test*np.var(res_new_0[:,2]),N_test*np.var(res_new[:,2]),N_test*np.var(res_new_1[:,2]),N_test*np.var(res_new_2[:,2]),N_test*np.var(res_new_3[:,2]))#,N_test*np.var(res_new_4[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(N_test*np.var(res_new_0[:,2]),N_test*np.var(res_new[:,2]),N_test*np.var(res_new_1[:,2]),N_test*np.var(res_new_2[:,2]),N_test*np.var(res_new_3[:,2]))#,N_test*np.var(res_new_4[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [res_new_0[:,2],res_new[:,2],res_new_1[:,2], res_new_2[:,2],res_new_3[:,2]]#,res_new_4[:,2]] \n",
    "#data = [res_new_1[:,2], res_new_2[:,2],res_new_3[:,2],res_new_4[:,2]] \n",
    "boxplot_ind(data, title, labels,path=\"./2d_nonsymmetric_potential_gamma_2nd_order__influence_upd_27.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
