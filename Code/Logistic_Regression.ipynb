{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.polynomial as P\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "#from sklearn.preprocessing import PolynomialFeatures\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import ZVnbrosse\n",
    "from potentials import GaussPotential,GaussMixture,GausMixtureIdent,GausMixtureSame,potentialRegression\n",
    "from samplers import MCMC_sampler,Generate_train,ULA_light\n",
    "from baselines import set_function,construct_ESVM_kernel,GenerateSigma,standartize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from martingale import approx_q,test_traj\n",
    "from optimize import Run_eval_test,optimize_parallel_new \n",
    "from utils import *\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"swiss\" # Switch between \"eeg\" and \"susy\" \n",
    "intercept = False # Do we include the intercept\n",
    "degree = 1 #order of CV's: 1 or 2 expected\n",
    "typ = \"logistic\" #logistic or probit are expected\n",
    "test_size = 10\n",
    "\n",
    "sampler = {\"sampler\":\"ULA\",\"burn_type\":\"full\",\"main_type\":\"full\"} # Sampling method\n",
    "\n",
    "# Switch between \"posterior_prob_point\", \"posterior_prob_mean\", \"posterior_prob_variance\", \"posterior_mean\"\n",
    "if typ == \"logistic\":\n",
    "    f_type = \"sum\"\n",
    "elif typ == \"probit\":\n",
    "    f_type = \"posterior_prob_mean_probit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (dataset == \"swiss\"):\n",
    "    data = pd.read_csv(\"./data/swiss.csv\",header=None)\n",
    "    outliers_inds = np.array([])\n",
    "    Y = data.iloc[:,-1]\n",
    "    X = data.iloc[:,:-1]\n",
    "elif (dataset == \"eeg\"):   \n",
    "    data = pd.read_csv(\"../iZAV_code/data/eeg.csv\",header=None)\n",
    "    outliers_inds = np.array([13179,11509,898,10386])\n",
    "    Y = data.iloc[:,-1]\n",
    "    X = data.iloc[:,:-1]\n",
    "elif (dataset == \"pima\"):\n",
    "    data = pd.read_csv(\"./data/pima.csv\",header=None)\n",
    "    outliers_inds = np.array([])\n",
    "    Y = data.iloc[:,-1]\n",
    "    X = data.iloc[:,:-1]\n",
    "elif (dataset == \"susy\"): \n",
    "    data = pd.read_csv(\"data/susy.csv\",header=None)\n",
    "    outliers_inds = np.array([267630])\n",
    "    Y = data.iloc[:,0]\n",
    "    X = data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the outliers\n",
    "if (outliers_inds.size!=0):\n",
    "    X_processed = np.delete(np.asarray(X),outliers_inds,0)\n",
    "    mask = np.ones(len(Y),dtype = bool)\n",
    "    mask[outliers_inds] = False\n",
    "    Y_processed = Y[mask]\n",
    "    Y_processed = np.asarray(Y_processed)\n",
    "    X_processed = np.asarray(X_processed)\n",
    "else:\n",
    "    Y_processed = np.asarray(Y)\n",
    "    X_processed = np.asarray(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if (f_type == \"posterior_mean\" or f_type == \"sum\"):\n",
    "#    X_train,X_train = standartize(X_processed,Y_processed,intercept=intercept)\n",
    "#    Y_train = Y_processed\n",
    "#else:\n",
    "#    X_train,X_test,Y_train,Y_test = train_test_split(X_processed,Y_processed,test_size=test_size,random_state=1812,stratify=Y_processed)\n",
    "#    X_train,X_test = standartize(X_train,X_test,intercept=intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = copy.deepcopy(X_processed)\n",
    "Y_train = copy.deepcopy(Y_processed)\n",
    "#poor man's normalization\n",
    "X_train = np.dot(X_train - np.mean(X_train, axis=0), np.diag(1./np.std(X_train, axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating potential\n",
    "Cur_pot = potentialRegression(Y_train, X_train, typ, print_info = True)\n",
    "d = Cur_pot.d\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_burn = 1*10**3 # Burn in period\n",
    "N_train = 1*10**4 # Number of samples on which we optimize\n",
    "N_test = 1*10**3 # Number of samples\n",
    "step = 0.1 # Step size\n",
    "n_traj_train = 5\n",
    "n_traj_test = 24 # Number of independent MCMC trajectories for test\n",
    "#f_type = \"sum\"\n",
    "K_max = 2 #max degree of Hermite polynomial\n",
    "S_max = 2 #max degree of polynomial during regression stage\n",
    "lag = 50 #maximal lag order\n",
    "b_n_train = 10 #lag-window size\n",
    "b_n_test = int(np.round(N_test**(0.33)))\n",
    "print(b_n_test)\n",
    "degree = 1\n",
    "x0 = np.zeros(d, dtype = float)\n",
    "fixed_start = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_seed = 777\n",
    "traj = np.zeros((n_traj_train,N_train,d),dtype = float)\n",
    "for i in range(n_traj_train):\n",
    "    cur_traj = ULA_light(r_seed+i,Cur_pot,step, N_burn, N_train, d, return_noise = False, x0 = x0, fixed_start = fixed_start)\n",
    "    traj[i] = copy.deepcopy(cur_traj)\n",
    "print(traj.shape)\n",
    "#traj = np.expand_dims(traj, axis=0)\n",
    "#rint(traj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (f_type == \"posterior_mean\" or f_type == \"sum\"):\n",
    "    inds_arr = np.array([1]) # Taking the second index (not intercept)\n",
    "    params = None\n",
    "else:\n",
    "    params = {\"X\":X_test,\"Y\":Y_test}\n",
    "    inds_arr = np.array([0])\n",
    "    \n",
    "f_vals = set_function(f_type,traj,inds_arr,params) \n",
    "#f_vals = traj[:,:,0]\n",
    "#f_vals = np.expand_dims(f_vals, axis=2)\n",
    "print(f_vals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate baselines (EVM and ESVM methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sampler[\"sampler\"] == \"ULA\":\n",
    "    res = Generate_train(1, sampler, Cur_pot, step, N_burn, N_train, d)\n",
    "    res = np.asarray(res)\n",
    "    traj_evm,traj_grad = res[:,0,:,:],res[:,1,:,:]\n",
    "else:\n",
    "    raise \"You should use ULA!\"\n",
    "    \n",
    "f_vals_evm = set_function(f_type,traj_evm,inds_arr,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_train_spec = construct_ESVM_kernel(N_train,b_n_train) #weight matrix for train\n",
    "W_test_spec = construct_ESVM_kernel(N_test,b_n_test) #weight matrix for test\n",
    "opt_structure_train = {\n",
    "    \"W\":W_train_spec,\n",
    "    \"n_restarts\": 3, # Number of restarts during optimization,\n",
    "    \"sigma\": 1.0, # Deviation of starting points\n",
    "    \"tol\": 1e-5, # Tolerance (for the norm of gradient)\n",
    "    \"alpha\": 0.0, # Ridge penalty for 2nd order control functionals\n",
    "    \"beta\": 10000.0 # smoothing parameter in the softmax\n",
    "}\n",
    "methods = [\"ESVM\",\"EVM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_dict = optimize_parallel_new(degree,inds_arr,f_vals_evm,traj_evm,traj_grad,opt_structure_train,methods)\n",
    "print(coef_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary and put respective matrices into it\n",
    "test_params = {\n",
    "    \"W\":W_test_spec,\n",
    "    \"step\":step,\n",
    "    \"burn_in\":N_burn,\n",
    "    \"n_test\":N_test,\n",
    "    \"dim\":d\n",
    "}\n",
    "\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res = trav.starmap(Run_eval_test, [(i,degree,sampler,methods,inds_arr,Cur_pot,test_params,coef_dict,params,f_type) for i in range (n_traj_test)])\n",
    "trav.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_enh = ['Vanilla'] + methods\n",
    "print(methods_enh)\n",
    "ints_result = {key: [] for key in methods_enh}\n",
    "vars_result = {key: [] for key in methods_enh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(res)):\n",
    "    for j in range(len(methods_enh)):\n",
    "        ints_result[methods_enh[j]].append(res[i][0][methods_enh[j]][0])\n",
    "        vars_result[methods_enh[j]].append(res[i][1][methods_enh[j]][0])\n",
    "for key in methods_enh:\n",
    "    ints_result[key] = np.asarray(ints_result[key])\n",
    "    vars_result[key] = np.asarray(vars_result[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli:: Optimize coefficients by solving regression with polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polynomial coefficients\n",
    "coefs_poly = approx_q(traj,f_vals,n_traj_train,lag,S_max)\n",
    "print(coefs_poly.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coefs_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(S_max)\n",
    "X_features = poly.fit_transform(traj[0])\n",
    "poly_1 = PolynomialFeatures(1)\n",
    "X_features_1 = poly_1.fit_transform(traj[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_lag = 1\n",
    "N_pts = 100\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Testing regression model\",fontsize=20)\n",
    "plt.plot(f_vals[0,cur_lag:N_pts,0],color='r',label='true function')\n",
    "plt.plot(X_features[:(N_pts-cur_lag),:] @ coefs_poly[cur_lag,:],color='g',label = '2-order approximation')\n",
    "plt.plot(X_features_1[:(N_pts-cur_lag),:] @ coefs_poly_1[cur_lag,:],color='b',label = '1-order approximation')\n",
    "plt.legend(loc = 'lower right',fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"4-nd order error: \",np.linalg.norm(f_vals[0,cur_lag:N_pts,0]-X_features[:(N_pts-cur_lag),:] @ coefs_poly[cur_lag,:]))\n",
    "print(\"1-st order error: \",np.linalg.norm(f_vals[0,cur_lag:N_pts,0]-X_features_1[:(N_pts-cur_lag),:] @ coefs_poly_1[cur_lag,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seed = 1453\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res = trav.starmap(test_traj, [(Cur_pot,coefs_poly,step,test_seed+i,lag,K_max,S_max,N_burn,N_test,d,f_type,inds_arr,params, x0, fixed_start) for i in range (n_traj_test)])\n",
    "trav.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_new = np.asarray(res)\n",
    "print(res_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_vanilla = np.var(res_new[:,0,:],axis = 0)\n",
    "vars_adj = np.var(res_new[:,1,:],axis = 0)\n",
    "#print(vars_vanilla)\n",
    "#print(vars_adj)\n",
    "print(np.mean(vars_adj[1:]/vars_vanilla[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vars_vanilla[-10:])\n",
    "print(vars_adj[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\n",
    "labels = ['Vanilla\\n ULA', 'ULA \\nwith MDCV', 'ULA \\nwith EVM','ULA\\nwith ESVM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [ints_result['Vanilla'][:,0],res_new[:,1,-1],ints_result['EVM'][:,0],ints_result['ESVM'][:,0]] \n",
    "boxplot_ind(data, title, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"\"\n",
    "labels = ['ULA \\nwith MDCV', 'ULA \\nwith EVM','ULA\\nwith ESVM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = [res_new[:,1,-1],ints_result['EVM'][:,0],ints_result['ESVM'][:,0]] \n",
    "boxplot_ind(data, title, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
