{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import RK45,solve_ivp\n",
    "from ODE_potentials import VanDerPolePotential,LotkiVolterraPotential\n",
    "from ODE_samplers import MALA_ODE,ULA_ODE,grad_ascent_ODE,run_eval_test,set_function\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "from zv_cv import Eval_ZVCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import copy\n",
    "\n",
    "from baselines import construct_ESVM_kernel, construct_Tukey_Hanning \n",
    "from optimize import optimize_parallel_new\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for van-der-Pole and Lotka-Volterra examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ = 'LV' #'LV' for Lotka-Volterra, 'VdP' for Van-der-Pole\n",
    "method = {\"sampler\":\"MALA\"} #switch between ULA and MALA\n",
    "f_type = \"sum_comps\"\n",
    "\n",
    "if typ == 'VdP':\n",
    "    #true parameter value\n",
    "    theta_star = 1.0\n",
    "    #initial coordiante and speed\n",
    "    y0 = np.array([0.0,2.0],dtype=float)\n",
    "    #error of measurements\n",
    "    sigma = 0.5\n",
    "    #prior variance\n",
    "    sigma_prior = 0.5\n",
    "elif typ == 'LV':\n",
    "    theta_star = np.array([0.6,0.025,0.8,0.025],dtype = float)\n",
    "    #initial number of victims and predators\n",
    "    y0 = np.array([30.0,4.0],dtype=float)\n",
    "    #setting prior parameters\n",
    "    sigma_prior = np.array([0.5,0.05,0.5,0.05],dtype = float)\n",
    "    mu_prior = np.array([1.0,0.05,1.0,0.05],dtype=float)\n",
    "    #measurements error\n",
    "    sigma = np.array([0.25,0.25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial and last time moments\n",
    "t0 = 0\n",
    "t_bound = 10\n",
    "N_steps = 10\n",
    "#moments of observations\n",
    "t_moments = np.linspace(t0,t_bound,N_steps+1)\n",
    "print(t_moments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating potentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if typ == 'VdP':\n",
    "    Cur_pot = VanDerPolePotential(sigma,sigma_prior,t_moments,theta_star,y0,t0,t_bound)\n",
    "elif typ == 'LV':\n",
    "    Cur_pot = LotkiVolterraPotential(sigma,mu_prior,sigma_prior,t_moments,theta_star,y0,t0,t_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling (currently with MALA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_seed = 666\n",
    "#burn-in period\n",
    "N_burn = 1*10**3\n",
    "#Train size\n",
    "N_train = 1*10**4\n",
    "#Test size\n",
    "N_test = 1*10**4\n",
    "#number of test trajectories\n",
    "n_traj = 1\n",
    "if typ == 'VdP':\n",
    "    #dimension\n",
    "    d = 1\n",
    "    #step size\n",
    "    step = 1e-3\n",
    "elif typ == 'LV':\n",
    "    #dimension\n",
    "    d = 4\n",
    "    #step size\n",
    "    step = 5e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct kernels and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if typ == 'VdP':\n",
    "    params_prior = {\"sigma\":sigma_prior}\n",
    "elif typ == 'LV':\n",
    "    params_prior = {\"mu\":mu_prior,\"sigma\":sigma_prior}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute starting point (maximum likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_steps_ascent = 5000\n",
    "traj,traj_grad = grad_ascent_ODE(1453,Cur_pot,step,params_prior,N_steps_ascent,d,typ)\n",
    "theta_mle = traj[-1,:]\n",
    "print(\"mle for parameters: \",theta_mle)\n",
    "Cur_pot.set_mle(theta_mle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_train = 5e-7\n",
    "inds_arr = np.array([0])\n",
    "params = {\"ind\":0}\n",
    "t_moments = None\n",
    "r_seed = 777\n",
    "traj = []\n",
    "traj_grad = []\n",
    "#generate data\n",
    "nbcores = multiprocessing.cpu_count()\n",
    "trav = Pool(nbcores)\n",
    "res = trav.starmap(ULA_ODE, [(r_seed+i,Cur_pot, step, params_prior, N_burn, N_train, d, typ) for i in range (n_traj)])\n",
    "trav.close()\n",
    "for i in range(len(res)):\n",
    "    traj.append(res[i][0])\n",
    "    traj_grad.append(res[i][1])\n",
    "    #print(\"accepted = \",res[i][2])\n",
    "traj = np.asarray(traj)\n",
    "traj_grad = np.asarray(traj_grad)\n",
    "traj_grad = (-1)*traj_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply control variates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(k, x):\n",
    "    if k==0:\n",
    "        return 1.0\n",
    "    if k ==1:\n",
    "        return x\n",
    "    if k==2:\n",
    "        return (x**2 - 1)/np.sqrt(2)\n",
    "    c = np.zeros(k+1,dtype = float)\n",
    "    c[k] = 1.0\n",
    "    h = P.hermite_e.hermeval(x,c) / np.sqrt(sp.special.factorial(k)) \n",
    "    return h\n",
    "\n",
    "def compute_H(k,x,d):\n",
    "    cur_prod = 1.0\n",
    "    for i in range(d):\n",
    "        cur_prod = cur_prod*H(k[i],x[:,i])\n",
    "    return cur_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lexicographical_2nd_order(d):\n",
    "    \"\"\"\n",
    "    function to generate lexigoraphical polynomials of 1st and 2nd order\n",
    "    \"\"\"\n",
    "    cur_list = []\n",
    "    for i in range(d):\n",
    "        cur_permute = np.zeros(d,dtype = int)\n",
    "        cur_permute[i] = 1\n",
    "        cur_list.append(np.copy(cur_permute))\n",
    "        cur_permute[i] = 0\n",
    "    for i in range(d):\n",
    "        cur_permute = np.zeros(d,dtype = int)\n",
    "        cur_permute[i] = 2\n",
    "        cur_list.append(np.copy(cur_permute))\n",
    "        cur_permute[i] = 1\n",
    "        for j in range(i+1,d):\n",
    "            cur_permute[j] = 1\n",
    "            cur_list.append(np.copy(cur_permute))\n",
    "            cur_permute[j] = 0\n",
    "    return cur_list\n",
    "\n",
    "a = generate_lexicographical_2nd_order(3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_traj(coefs_poly_regr,gamma,r_seed,lag,d,N_test,x0):\n",
    "    \"\"\"\n",
    "    function to perform 1-dimensional martingale decomposition\n",
    "    \"\"\"\n",
    "    X_test,Noise = generate_traj(x0,N_test,gamma,r_seed,d)\n",
    "    test_stat_vanilla = np.zeros(N_test,dtype = float)\n",
    "    test_stat_vr = np.zeros_like(test_stat_vanilla)\n",
    "    #compute number of basis polynomials\n",
    "    basis_funcs = generate_lexicographical_2nd_order(d)\n",
    "    num_basis_funcs = len(basis_funcs)\n",
    "    #compute polynomials of noise variables Z_l\n",
    "    poly_vals = np.zeros((num_basis_funcs,N_test), dtype = float)\n",
    "    for k in range(len(basis_funcs)):\n",
    "        poly_vals[k,:] = compute_H(basis_funcs[k],Noise,d)\n",
    "    #initialize function\n",
    "    f_vals_vanilla = np.sum(X_test**2,axis=1)\n",
    "    #array to store control variates values\n",
    "    cvfs = np.zeros_like(f_vals_vanilla)\n",
    "    #compute coeffitients bar_a\n",
    "    bar_a_1st_order = np.zeros((lag,d,N_test),dtype=float)\n",
    "    bar_a_2nd_order = np.zeros((lag,d,d,N_test),dtype=float)\n",
    "    #preprocessing \n",
    "    X_test = np.concatenate((x0.reshape(1,d),X_test),axis=0)\n",
    "    coefs_poly_1st_order = np.zeros((lag,d),dtype=float)\n",
    "    coefs_poly_1st_order = coefs_poly_regr[:,1:d+1]\n",
    "    coefs_poly_2nd_order = np.zeros((lag,d,d),dtype=float)\n",
    "    counter = 0\n",
    "    for i in range(d):\n",
    "        for j in range(i,d):\n",
    "            coefs_poly_2nd_order[:,i,j] = coefs_poly_regr[:,d+1+counter]\n",
    "            counter += 1\n",
    "    for i in range(lag):\n",
    "        #first-order coefficients\n",
    "        for j in range(d):\n",
    "            bar_a_1st_order[i,j,:] = coefs_poly_1st_order[i,j]*np.sqrt(gamma)*sigma(X_test[:-1])[:,j]\n",
    "            #sum more coefficients\n",
    "            for k in range(j):\n",
    "                bar_a_1st_order[i,j,:] += coefs_poly_2nd_order[i,k,j]*np.sqrt(gamma)*sigma(X_test[:-1])[:,j]*((X_test[:-1]+gamma*b(X_test[:-1]))[:,k])\n",
    "            #diagonal part\n",
    "            bar_a_1st_order[i,j] += 2*coefs_poly_2nd_order[i,j,j]*np.sqrt(gamma)*sigma(X_test[:-1])[:,j]*((X_test[:-1]+gamma*b(X_test[:-1]))[:,j])\n",
    "            #sum more coefficients\n",
    "            for k in range(j+1,d):\n",
    "                bar_a_1st_order[i,j] += coefs_poly_2nd_order[i,j,k]*np.sqrt(gamma)*sigma(X_test[:-1])[:,j]*((X_test[:-1]+gamma*b(X_test[:-1]))[:,k])\n",
    "            #second-order coefficients, to be filled\n",
    "            bar_a_2nd_order[i,j,j,:] = coefs_poly_2nd_order[i,j,j]*np.sqrt(2)*gamma*sigma(X_test[:-1])[:,j]\n",
    "            for k in range(j+1,d):\n",
    "                bar_a_2nd_order[i,j,k,:] = coefs_poly_2nd_order[i,j,k]*gamma*sigma(X_test[:-1])[:,j]*sigma(X_test[:-1])[:,k]\n",
    "        \"\"\"\n",
    "        bar_a_0_1[i,1:] = coefs_poly_regr[i,1]*cov[0,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,0]+\\\n",
    "                        coefs_poly_regr[i,2]*cov[1,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,1]+\\\n",
    "                        2*coefs_poly_regr[i,3]*cov[0,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,0]*(X_test[:-1]+gamma*b(X_test[:-1]))[:,0]+\\\n",
    "                        coefs_poly_regr[i,4]*(((X_test[:-1]+gamma*b(X_test[:-1]))[:,0])*sigma(X_test[:-1])[:,1]*np.sqrt(gamma)*cov[1,1] +\\\n",
    "                                             ((X_test[:-1]+gamma*b(X_test[:-1]))[:,1])*sigma(X_test[:-1])[:,0]*np.sqrt(gamma)*cov[0,1])+\\\n",
    "                        2*coefs_poly_regr[i,5]*cov[1,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,1]*(X_test[:-1]+gamma*b(X_test[:-1]))[:,1]\n",
    "        bar_a_0_1[i,0] = coefs_poly_regr[i,1]*cov[0,1]*np.sqrt(gamma)*sigma(x0)[0]+\\\n",
    "                        coefs_poly_regr[i,2]*cov[1,1]*np.sqrt(gamma)*sigma(x0)[1]+\\\n",
    "                        2*coefs_poly_regr[i,3]*cov[0,1]*np.sqrt(gamma)*sigma(x0)[0]*(x0+gamma*b(x0))[0]+\\\n",
    "                        coefs_poly_regr[i,4]*(((x0+gamma*b(x0))[0])*sigma(x0)[1]*np.sqrt(gamma)*cov[1,1] +\\\n",
    "                                             ((x0+gamma*b(x0))[1])*sigma(x0)[0]*np.sqrt(gamma)*cov[0,1])+\\\n",
    "                        2*coefs_poly_regr[i,5]*cov[1,1]*np.sqrt(gamma)*sigma(x0)[1]*(x0+gamma*b(x0))[1]\n",
    "        #coefficients with H_1_0\n",
    "        bar_a_1_0[i,1:] = coefs_poly_regr[i,1]*cov[0,0]*np.sqrt(gamma)*sigma(X_test[:-1])[:,0]+\\\n",
    "                        coefs_poly_regr[i,2]*cov[0,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,1]+\\\n",
    "                        2*coefs_poly_regr[i,3]*cov[0,0]*np.sqrt(gamma)*sigma(X_test[:-1])[:,0]*(X_test[:-1]+gamma*b(X_test[:-1]))[:,0]+\\\n",
    "                        coefs_poly_regr[i,4]*(((X_test[:-1]+gamma*b(X_test[:-1]))[:,0])*sigma(X_test[:-1])[:,1]*np.sqrt(gamma)*cov[0,1] +\\\n",
    "                                             ((X_test[:-1]+gamma*b(X_test[:-1]))[:,1])*sigma(X_test[:-1])[:,0]*np.sqrt(gamma)*cov[0,0])+\\\n",
    "                        2*coefs_poly_regr[i,5]*cov[0,1]*np.sqrt(gamma)*sigma(X_test[:-1])[:,1]*(X_test[:-1]+gamma*b(X_test[:-1]))[:,1]\n",
    "        bar_a_1_0[i,0] = coefs_poly_regr[i,1]*cov[0,0]*np.sqrt(gamma)*sigma(x0)[0]+\\\n",
    "                        coefs_poly_regr[i,2]*cov[0,1]*np.sqrt(gamma)*sigma(x0)[1]+\\\n",
    "                        2*coefs_poly_regr[i,3]*cov[0,0]*np.sqrt(gamma)*sigma(x0)[0]*(x0+gamma*b(x0))[0]+\\\n",
    "                        coefs_poly_regr[i,4]*(((x0+gamma*b(x0))[0])*sigma(x0)[1]*np.sqrt(gamma)*cov[0,1] +\\\n",
    "                                             ((x0+gamma*b(x0))[1])*sigma(x0)[0]*np.sqrt(gamma)*cov[0,0]) +\\\n",
    "                        2*coefs_poly_regr[i,5]*cov[0,1]*np.sqrt(gamma)*sigma(x0)[1]*(x0+gamma*b(x0))[1]\n",
    "        #second-order coefficients\n",
    "        bar_a_1_1[i,1:] = 2*coefs_poly_regr[i,3]*gamma*(sigma(X_test[:-1])[:,0])**2*cov[0,0]*cov[0,1]+\\\n",
    "                        coefs_poly_regr[i,4]*gamma*(sigma(X_test[:-1])[:,0])*(sigma(X_test[:-1])[:,1])*(cov[0,1]**2 + cov[0,0]*cov[1,1])+\\\n",
    "                        2*coefs_poly_regr[i,5]*gamma*(sigma(X_test[:-1])[:,1])**2*cov[1,1]*cov[0,1]\n",
    "        bar_a_1_1[i,0] = 2*coefs_poly_regr[i,3]*gamma*(sigma(x0)[0])**2*cov[0,0]*cov[0,1]+\\\n",
    "                        coefs_poly_regr[i,4]*gamma*(sigma(x0)[0])*(sigma(x0)[1])*(cov[0,1]**2 + cov[0,0]*cov[1,1])+\\\n",
    "                        2*coefs_poly_regr[i,5]*gamma*(sigma(x0)[1])**2*cov[1,1]*cov[0,1]\n",
    "        #coefficients with H_2_0\n",
    "        bar_a_2_0[i,1:] = np.sqrt(2)*coefs_poly_regr[i,3]*gamma\n",
    "        #coefficients with H_0_2\n",
    "        bar_a_0_2[i,1:] = np.sqrt(2)*coefs_poly_regr[i,5]*gamma\n",
    "        \"\"\"\n",
    "    #bar_a_1_0 = bar_a_1_0*poly_vals[0,:]\n",
    "    #bar_a_0_1 = bar_a_0_1*poly_vals[1,:]\n",
    "    #bar_a_1_1 = bar_a_1_1*poly_vals[2,:]\n",
    "    #bar_a_2_0 = bar_a_2_0*poly_vals[3,:]\n",
    "    #bar_a_0_2 = bar_a_0_2*poly_vals[4,:]\n",
    "    counter = 0\n",
    "    for i in range(d):\n",
    "        bar_a_1st_order[:,i,:] = poly_vals[i,:]*bar_a_1st_order[:,i,:]\n",
    "        bar_a_2nd_order[:,i,i,:] = poly_vals[d + d*(d+1)//2 - (d-i)*(d-i+1)//2,:]*bar_a_2nd_order[:,i,i,:]\n",
    "        counter += 1\n",
    "        for j in range(i+1,d):\n",
    "            bar_a_2nd_order[:,i,j,:] = poly_vals[d+counter]*bar_a_2nd_order[:,i,j,:]\n",
    "            counter += 1\n",
    "    #compute martingale sums\n",
    "    M_n_1st = 0.0\n",
    "    M_n_2nd = 0.0\n",
    "    for l in range(N_test):\n",
    "        for r in range(min(N_test-l,lag)):\n",
    "            M_n_1st += np.sum(bar_a_1st_order[r,:,l])\n",
    "            M_n_2nd += np.sum(bar_a_2nd_order[r,:,:,l])\n",
    "    return np.mean(f_vals_vanilla), np.mean(f_vals_vanilla)-(M_n_1st)/N_test, np.mean(f_vals_vanilla)-(M_n_1st+M_n_2nd)/N_test\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_q(X_train,Y_train,N_traj_train,lag,max_deg):\n",
    "    \"\"\"\n",
    "    Function to regress q functions on a polynomial basis;\n",
    "    Args:\n",
    "        X_train - train tralectory;\n",
    "        Y_train - function values;\n",
    "        N_traj_train - number of training trajectories;\n",
    "        lag - truncation point for coefficients, those for |p-l| > lag are set to 0;\n",
    "        max_deg - maximum degree of polynomial in regression\n",
    "    \"\"\"\n",
    "    dim = X_train[0,:].shape[0]\n",
    "    #print(\"dimension = \",dim)\n",
    "    coefs_poly = np.array([])\n",
    "    for i in range(lag):\n",
    "        x_all = np.array([])\n",
    "        y_all = np.array([])\n",
    "        for j in range(N_traj_train):\n",
    "            y = Y_train[j,i:,0]\n",
    "            if i == 0:\n",
    "                x = X_train[j,:]\n",
    "            else:\n",
    "                x = X_train[j,:-i]\n",
    "            #concatenate results\n",
    "            if x_all.size == 0:\n",
    "                x_all = x\n",
    "            else:\n",
    "                x_all = np.concatenate((x_all,x),axis = 0)\n",
    "            y_all = np.concatenate([y_all,y])\n",
    "        #should use polyfeatures here\n",
    "        #print(\"variance: \",np.var(y_all))\n",
    "        #print(y_all[:50])\n",
    "        poly = PolynomialFeatures(max_deg)\n",
    "        X_features = poly.fit_transform(x_all)\n",
    "        #print(X_features.shape)\n",
    "        lstsq_results = np.linalg.lstsq(X_features,y_all,rcond = None)\n",
    "        coefs = copy.deepcopy(lstsq_results[0])\n",
    "        coefs.resize((1,X_features.shape[1]))           \n",
    "        if coefs_poly.size == 0:\n",
    "            coefs_poly = copy.deepcopy(coefs)\n",
    "        else:\n",
    "            coefs_poly = np.concatenate((coefs_poly,coefs),axis=0)\n",
    "    return coefs_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = traj\n",
    "print(X_train.shape)\n",
    "Y_train = X_train[:,:,0].reshape((1,-1,1))\n",
    "print(Y_train.shape)\n",
    "lag = 100\n",
    "S_max = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polynomial coefficients\n",
    "coefs_poly = approx_q(X_train,Y_train,n_traj,lag,S_max)\n",
    "#print(coefs_poly.shape)\n",
    "print(coefs_poly)\n",
    "regr_vals = np.zeros((lag,X_train.shape[1]),dtype=float)\n",
    "poly = PolynomialFeatures(S_max)\n",
    "features = poly.fit_transform(X_train[0])\n",
    "#features = np.zeros((X_train.shape[1],6),dtype=float)\n",
    "#features[:,0] = 1.0\n",
    "#features[:,1:3] = X_train[0,:,:]\n",
    "#features[:,3] = X_train[0,:,0]**2 \n",
    "#features[:,4] = X_train[0,:,0]*X_train[0,:,1]\n",
    "#features[:,5] = X_train[0,:,1]**2\n",
    "for i in range(len(regr_vals)):\n",
    "    regr_vals[i,:] = np.sum(coefs_poly[i,:]*features,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_lag = 99\n",
    "N_pts = 500\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Testing regression model\",fontsize=20)\n",
    "plt.plot(Y_train[0,cur_lag:N_pts+cur_lag,0],color='r',label='true function')\n",
    "plt.plot(regr_vals[cur_lag,:N_pts],color='g',label = 'practical approximation')\n",
    "plt.legend(loc = 'upper left',fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
