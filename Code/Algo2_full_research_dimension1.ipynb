{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import Algo2\n",
    "import Algo1\n",
    "import ULA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from joblib import Parallel, delayed\n",
    "import ZVnbrosse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(Algo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 1\n",
    "h = 0.1\n",
    "   \n",
    "def f_grad(x):\n",
    "    a = 1 / np.sqrt(2)\n",
    "    return x-a+2*a/(1 + np.exp(2* (x * a)))\n",
    "\n",
    "def f(x):\n",
    "    a = 1 / np.sqrt(2)\n",
    "    return 1/2 * (x-a)**2 - np.log(1 + np.exp(-2 * x * a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(-5, 5, 0.01)\n",
    "s = np.array(list(map(f, t)))\n",
    "\n",
    "plt.plot(t, s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(-5.0, 5.0, 0.01)\n",
    "s = np.array(list(map(f_grad, t)))\n",
    "\n",
    "plt.plot(t, s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of $\\bar{Q}_{l,n}(x)$\n",
    "\n",
    "$$\\bar{Q}_{l,n}^N (x) = \\mathbb{E} \\left [\\sum_{p = l}^{N+n} \\frac{1}{n} f(X_p) | X_l = x \\right] \\quad \\forall l = N+1, \\dots, N+n$$\n",
    "\n",
    "In order, to approximate functions $\\bar{Q}_{l,n}^N(x)$, for all $l$ I generated trajectories started from each point of the grid and estimated the functions. Particularly:\n",
    "\n",
    "we have grid on $I = \\left[-5,  5 \\right]$\n",
    "\n",
    "for each point $x \\in I$, for each $l$ I generated $N_{train} = 100 $ trajectories of length $n+N-l$:\n",
    "\n",
    "$$X^{x, (i)}_0 = x$$\n",
    "\n",
    "$$X^{x, (i)}_p = X_{p-1}^{x,(i)} - h  \\mu( X_{p-1}^{x,(i)}) + \\sqrt{h} Z_p^{(i)}$$\n",
    "\n",
    "$$ \\forall p = 1, \\dots, n \\text{ and }  i = 1, \\dots , N_{train}$$\n",
    "\n",
    "Then I estimate:\n",
    "$$\\bar{Q}_{l, n}^N (x) = \\frac{1}{N_{train}} \\sum_{i = 1}^{N_{train}}\\sum_{p = 0}^{n-l} \\frac{1}{n} X_p^{x, (i)} \\quad \\forall x \\in I$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "N_train = 50\n",
    "\n",
    "grid = np.arange(-5,5,0.2)\n",
    "\n",
    "def q_l_by_grid(grid, l, n, N_train, h):\n",
    "    np.random.seed(l)\n",
    "    noise = np.random.randn(N_train, n-l)\n",
    "    trajectories_on_grid = np.zeros((grid.shape[0], N_train, n-l))\n",
    "    for j in range(N_train):\n",
    "        trajectories_on_grid[:,j,0] = grid\n",
    "    for i in range(grid.shape[0]):\n",
    "        for j in range(N_train):\n",
    "            for m in range(1,n-l):\n",
    "                trajectories_on_grid[i,j,m] = trajectories_on_grid[i,j,m-1] - h/2 * f_grad(trajectories_on_grid[i,j,m-1]) \\\n",
    "                    + np.sqrt(h) * noise[j,m]\n",
    "    return ((trajectories_on_grid[:,:,1:]).sum(axis = 2) / n).mean(axis = 1) + grid/n\n",
    "#     return trajectories_on_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_grid = np.zeros((n, grid.shape[0]))\n",
    "for l in tqdm(range(n)):\n",
    "    Q_grid[l] = q_l_by_grid(grid, l, n, N_train, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Q_grid.npy', Q_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_grid = np.load('Q_grid.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some plots for $\\bar{Q}_{l,n} (x)$ for $l \\in \\left\\{1, 20, 50, 100,150,200, 230, 250 \\right\\}$ and $n = 250$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for l in range(10):\n",
    "    plt.plot(grid, Q_grid[l], label = r\"$l = {}$\".format(l+1))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.xlim(-1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for l in range(250, 260):\n",
    "    plt.plot(grid, Q_grid[l], label = r\"$l = {}$\".format(l+1))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.xlim(-1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for l in range(490, 500):\n",
    "    plt.plot(grid, Q_grid[l], label = r\"$l = {}$\".format(l+1))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.xlim(-1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for l in [300, 350, 400, 450, 495, 498, 499]:\n",
    "    plt.plot(grid, Q_grid[l], label = r\"$l = {}$\".format(l+1))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.xlim(-1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function $\\tilde{\\bar{Q}}_{l,n}(x)$, which finds $i$ such that: $x_i < x < x_{i+1}$ where $x_i, x_{i+1} \\in I$\n",
    "\n",
    "$$\\tilde{\\bar{Q}}_{l,n}(x) = \\frac{\\bar{Q}_{l,n}(x_i) + \\bar{Q}_{l,n}(x_{i+1})}{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_l(grid, Q_grid, x, l):\n",
    "    pos = np.searchsorted(grid, x)\n",
    "#     print (pos)\n",
    "    if pos > 0:\n",
    "        return Q_grid[l, pos-1:pos+1].mean()\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with approximation using regression on pregenerated train trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2342)\n",
    "X, G, Z = ULA.ULA_with_burnin(d=dim, step=h, burn_in=10000, n=1000000,f_grad=f_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_weighted_estimator(X):\n",
    "    return X.sum(axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "XX, GG, ZZ = ULA.generate_train_trajectories(X, N_train=1000,d = dim, step = h, n = n, f_grad=f_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(Algo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = 1\n",
    "Betas, degrees = Algo2.Q_l_fit(XX, f_target=\"sum\", max_deg = deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_l_predict(x, l, Betas, max_deg):\n",
    "    poly = PolynomialFeatures(max_deg)\n",
    "    x_pol = poly.fit_transform(np.array(x).reshape(1,-1))\n",
    "    beta = Betas[l]\n",
    "    return (x_pol @ beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "q_l_predict_plot = np.zeros_like(grid)\n",
    "\n",
    "for l in [300, 350, 400, 450, 495, 498, 499]:\n",
    "    for i in range(grid.shape[0]):\n",
    "        q_l_predict_plot[i] = Q_l_predict(grid[i], l, Betas, deg) \n",
    "    plt.plot(grid, Q_grid[l], label = \"by grid, l = {}\".format(l+1))\n",
    "    plt.scatter(grid, q_l_predict_plot, label = \"by regression, l = {}\".format(l+1), )\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "q_l_predict_plot = np.zeros_like(grid)\n",
    "\n",
    "for l in [0, 50, 100]:\n",
    "    for i in range(grid.shape[0]):\n",
    "        q_l_predict_plot[i] = Q_l_predict(grid[i], l, Betas, deg) \n",
    "    plt.plot(grid, Q_grid[l], label = \"by grid, l = {}\".format(l+1))\n",
    "    plt.scatter(grid, q_l_predict_plot, label = \"by regression, l = {}\".format(l+1), )\n",
    "plt.legend()\n",
    "# plt.xlim(-3,3)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Ground truth\" result for dimension 1\n",
    "####  Suppose we have markov chain with gaussian mixture distribution:\n",
    "\n",
    "$X_1, X_2, \\dots, X_n$\n",
    "\n",
    "where $n$ = 500\n",
    "\n",
    "$f(x) = x$\n",
    "\n",
    "$\\gamma_i = h$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. \n",
    "\n",
    "Suppose we have estimation for $\\bar{Q}_{l, n}(x) \\quad \\forall l $ on grid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "$$a_{l,n}^k(x) = \\mathbb{E}_{\\xi} \\left[ \\phi_k(\\xi) \\bar{Q}_{l,n} (x - h\\mu(x) + \\sqrt{h}\\xi)\\right]= \\int_{-\\infty}^{\\infty} \\phi_k(y) \\bar{Q}_{l,n} (x - h\\mu(x) + \\sqrt{h}y) \\varphi(y) dy$$\n",
    "\n",
    "where $$\\varphi(y) = \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{y^2}{2}}$$\n",
    "\n",
    "Explicit Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "from scipy.stats import multivariate_normal as mvnorm\n",
    "\n",
    "def integrand(y, x, x_grad, l):\n",
    "    x_next = np.array([x - h/2 * x_grad + np.sqrt(h) * y])\n",
    "    return Q_l(grid, Q_grid, x_next[0], l) * y * mvnorm.pdf(y, mean=0, cov=1)\n",
    "\n",
    "def a_lk_explicit(x, x_grad, l):\n",
    "    return quad(integrand, -4, 4, args=(x,x_grad,l))[0]\n",
    "\n",
    "def M_bias_gt(traj, traj_grad, traj_noise):\n",
    "    S = 0\n",
    "    for k in range (1):\n",
    "        for i in range(1,traj.shape[0]):\n",
    "            S = S + a_lk_explicit(traj[i-1], traj_grad[i-1], i) *  Algo2.H(1,traj_noise[i])\n",
    "    return S\n",
    "\n",
    "def estimator_gt(test_traj, test_traj_grad, test_traj_noise, n_jobs = 8):\n",
    "    N_test = test_traj.shape[0]\n",
    "    M_results = Parallel(n_jobs = n_jobs)(delayed(M_bias_gt)(test_traj[i], test_traj_grad[i], test_traj_noise[i])for i in range(N_test))\n",
    "    return np.array(M_results).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "a_lk_explicit_plot = np.zeros_like(grid)\n",
    "for l in [0, 50, 100]:\n",
    "    for i in range(grid.shape[0]):\n",
    "        a_lk_explicit_plot[i] = a_lk_explicit(grid[i],f_grad(grid[i]), l) \n",
    "    plt.plot(grid, a_lk_explicit_plot, label = \"by explicit integration, l = {}\".format(l+1))\n",
    "plt.legend()\n",
    "# plt.xlim(-3,3)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimator(XX):\n",
    "    Pi = np.empty(XX.shape[0])\n",
    "    for i in tqdm(range(XX.shape[0])):\n",
    "        Pi[i] = local_weighted_estimator(XX[i])\n",
    "    return Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "N_test = 50\n",
    "XX_test, GG_test, ZZ_test = ULA.generate_test_trajetories(N_test=N_test, d =dim, step=h, \n",
    "                                                          burn_in=10000, n = n, f_grad=f_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_test = estimator(XX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_test_gt = estimator_gt(XX_test, GG_test, ZZ_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_test_reg = Algo2.estimator_bias(np.array([[1]], dtype=np.int16),XX_test, GG_test, ZZ_test,h, degrees, Betas, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZVpolyOne(traj, traj_grad):\n",
    "    n, d = traj.shape\n",
    "    samples = traj.sum(axis = 1).reshape(-1,1)\n",
    "    cov1 = np.var(traj_grad)\n",
    "    A = 1 / cov1\n",
    "    covariance = np.cov(np.concatenate((-traj_grad, samples), axis=1), rowvar=False)\n",
    "    paramZV1 = -np.dot(A,covariance[:d, d:])\n",
    "    ZV1 = samples - np.dot(traj_grad, paramZV1)\n",
    "    mean_ZV1 = np.mean(ZV1, axis = 0)\n",
    "    return mean_ZV1\n",
    "\n",
    "res_zv_1 = []\n",
    "for i in range (XX_test.shape[0]):\n",
    "    res_zv_1.append(ZVpolyOne(XX_test[i].reshape(-1,dim), GG_test[i].reshape(-1,dim)))\n",
    "res_zv_1 = np.array(res_zv_1).reshape(-1)\n",
    "\n",
    "res_zv_2 = []\n",
    "for i in range (XX_test.shape[0]):\n",
    "    res_zv_2.append(ZVnbrosse.ZVpolyTwo(XX_test[i].reshape(-1,dim), GG_test[i].reshape(-1,dim),\"sum\"))\n",
    "res_zv_2 = np.array(res_zv_2).reshape(-1)\n",
    "\n",
    "res_cv_1 = []\n",
    "for i in range (XX_test.shape[0]):\n",
    "    res_cv_1.append(ZVnbrosse.CVpolyOne(XX_test[i].reshape(-1,dim), GG_test[i].reshape(-1,dim),\"sum\"))\n",
    "res_cv_1 = np.array(res_cv_1).reshape(-1)\n",
    "\n",
    "res_cv_2 = []\n",
    "for i in range (XX_test.shape[0]):\n",
    "    res_cv_2.append(ZVnbrosse.CVpolyTwo(XX_test[i].reshape(-1,dim), GG_test[i].reshape(-1,dim), \"sum\"))\n",
    "res_cv_2 = np.array(res_cv_2).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [P_test]\n",
    "# all_data = []\n",
    "all_data.append(P_test - M_test_gt)\n",
    "all_data.append(P_test - M_test_reg)\n",
    "all_data.append(res_zv_1)\n",
    "all_data.append(res_zv_2)\n",
    "all_data.append(res_cv_1)\n",
    "all_data.append(res_cv_2)\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.violinplot(all_data, showmeans=True, showmedians=False)\n",
    "plt.title('violin plot')\n",
    "plt.xticks(np.arange(1,8), ('pi', 'CV_GT','CV_Reg',  'ZV_1', 'ZV_2', 'CV_1', 'CV_2'))\n",
    "# plt.xticks(np.arange(1,6), ('CV_B', 'ZV_1', 'ZV_2', 'CV_1', 'CV_2'))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Variance of ULA = ', P_test.var(ddof=1))\n",
    "\n",
    "print ('Variance on test trajectories using grid + explicit integration =',(P_test - M_test_gt).var(ddof = 1))\n",
    "\n",
    "print ('Variance of ALgo2 (polynomial regression) = ',(P_test - M_test_reg).var(ddof = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Variance of ALgo1 (polynomial regression) = ',(P_test - M_test_1).var(ddof = 1))\n",
    "print (res_zv_1.var(ddof = 1))\n",
    "print (res_cv_1.var(ddof = 1))\n",
    "print (res_zv_2.var(ddof = 1))\n",
    "print (res_cv_2.var(ddof = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Code import Algo1\n",
    "\n",
    "f_target = 'sum'\n",
    "\n",
    "Betas_1, degrees_1 = Algo1.G_pml_fit_mean(XX,f_target, max_deg = deg)\n",
    "\n",
    "M_test_1 = Algo1.estimator_bias(np.array([[1]], dtype=np.int16), XX_test, GG_test, ZZ_test, h, degrees_1,Betas_1,100, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [P_test]\n",
    "# all_data = []\n",
    "all_data.append(P_test - M_test_1)\n",
    "all_data.append(res_zv_1)\n",
    "all_data.append(res_zv_2)\n",
    "all_data.append(res_cv_1)\n",
    "all_data.append(res_cv_2)\n",
    "    \n",
    "plt.figure(figsize=(10,10))\n",
    "plt.violinplot(all_data, showmeans=True, showmedians=False)\n",
    "plt.title('violin plot')\n",
    "plt.xticks(np.arange(1,8), ('pi', 'CV_B_1', 'ZV_1', 'ZV_2', 'CV_1', 'CV_2'))\n",
    "# plt.xticks(np.arange(1,6), ('CV_B', 'ZV_1', 'ZV_2', 'CV_1', 'CV_2'))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $a_{l,k}(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_lk_by_grid(grid, l, n, N_train):\n",
    "    np.random.seed(42)\n",
    "    noise = np.random.randn(N_train, n-l+1)\n",
    "    trajectories_on_grid = np.zeros((grid.shape[0], N_train, n-l+1))\n",
    "    a_lk_on_grid = np.zeros_like(grid)\n",
    "    for j in range(N_train):\n",
    "        trajectories_on_grid[:,j,0] = grid\n",
    "    for i in range(grid.shape[0]):\n",
    "        for j in range(N_train):\n",
    "            for m in range(1,n-l):\n",
    "                trajectories_on_grid[i,j,m] = trajectories_on_grid[i,j,m-1] - h/2 * f_grad(trajectories_on_grid[i,j,m-1]) \\\n",
    "                    + np.sqrt(h) * noise[j,m]\n",
    "                    \n",
    "    tmp = trajectories_on_grid[:,:,1:].sum(axis = 2) / n\n",
    "\n",
    "    for i in range(grid.shape[0]):\n",
    "        for j in range(N_train):\n",
    "            tmp[i,j] = tmp[i,j] * noise[j, 0]\n",
    "            \n",
    "    return tmp.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_grid = np.zeros((n, grid.shape[0]))\n",
    "for l in tqdm(range(1,n)):\n",
    "    a_grid[l] = a_lk_by_grid(grid, l, n, N_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for l in [1,19,50, 100,150, 200,249]:\n",
    "    plt.scatter(grid, a_grid[l], label = r\"$l = {}$\".format(l+1))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.xlim(-1,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of $Q_{p,l}$ and Algo1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Q_{p,l}(x) = \\mathbb{E} \\left[ f(X_p) \\mid X_l =x\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_pl_by_grid(grid, p, l, n, N_train, h):\n",
    "    np.random.seed(l)\n",
    "    noise = np.random.randn(N_train, p-l+1)\n",
    "    trajectories_on_grid = np.zeros((grid.shape[0], N_train, p-l+1))\n",
    "    for j in range(N_train):\n",
    "        trajectories_on_grid[:,j,0] = grid\n",
    "    for i in range(grid.shape[0]):\n",
    "        for j in range(N_train):\n",
    "            for m in range(1,p-l+1):\n",
    "                trajectories_on_grid[i,j,m] = trajectories_on_grid[i,j,m-1] - h/2 * f_grad(trajectories_on_grid[i,j,m-1]) \\\n",
    "                    + np.sqrt(h) * noise[j,m]\n",
    "    return (trajectories_on_grid[:,:,-1]).mean(axis = 1)\n",
    "#     return trajectories_on_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_pl_grid = np.zeros((n, grid.shape[0]))\n",
    "for p in tqdm(range(1,n)):\n",
    "    Q_pl_grid[p] = q_pl_by_grid(grid, p, 0, n, N_train, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "q_pl_predict_plot = np.zeros_like(grid)\n",
    "\n",
    "for p in range(100, 200, 10):\n",
    "    for i in range(grid.shape[0]):\n",
    "        q_pl_predict_plot[i] = Algo1.G_pml_predict(grid[i], p, Betas_2, deg) \n",
    "    plt.plot(grid, Q_pl_grid[p], label = \"by grid, l = {}\".format(p+1))\n",
    "    plt.scatter(grid, q_pl_predict_plot, label = \"by regression, l = {}\".format(p+1), )\n",
    "plt.legend()\n",
    "plt.xlim(-2,2)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "q_pl_predict_plot = np.zeros_like(grid)\n",
    "\n",
    "for p in range(400, 500, 10):\n",
    "    for i in range(grid.shape[0]):\n",
    "        q_pl_predict_plot[i] = Algo1.G_pml_predict(grid[i], p, Betas_2, deg) \n",
    "    plt.plot(grid, Q_pl_grid[p], label = \"by grid, l = {}\".format(p+1))\n",
    "    plt.scatter(grid, q_pl_predict_plot, label = \"by regression, l = {}\".format(p+1), )\n",
    "plt.legend()\n",
    "# plt.xlim(-2,2)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth for algo1 ($Q_{p,l}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand_2(y, x, x_grad, l):\n",
    "    x_next = np.array([x - h/2 * x_grad + np.sqrt(h) * y])\n",
    "    return Q_l(grid, Q_pl_grid, x_next[0], l) * y * mvnorm.pdf(y, mean=0, cov=1)\n",
    "\n",
    "def a_plk_explicit(x, x_grad, p, l):\n",
    "    return quad(integrand_2, -4, 4, args=(x,x_grad,p-l))[0]\n",
    "\n",
    "def M_bias_gt_2(traj, traj_grad, traj_noise, n_tilde = 100):\n",
    "    S = 0\n",
    "    for k in range (1):\n",
    "        for p in range(traj.shape[0]):\n",
    "            for l in range(p+1):\n",
    "                if (p-l<n_tilde): \n",
    "                    S = S + a_plk_explicit(traj[l-1,0], traj_grad[l-1,0], p, l) *  Algo1.H(1,traj_noise[l])\n",
    "    return S/traj.shape[0]\n",
    "\n",
    "\n",
    "def estimator_gt_2(test_traj, test_traj_grad, test_traj_noise, n_jobs = 8):\n",
    "    N_test = test_traj.shape[0]\n",
    "    M_results = Parallel(n_jobs = n_jobs)(delayed(M_bias_gt_2)(test_traj[i], test_traj_grad[i], test_traj_noise[i])for i in range(N_test))\n",
    "    return np.array(M_results).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "i_test = 5\n",
    "time_1 = timeit.default_timer()\n",
    "p = local_weighted_estimator(XX_test[i_test])\n",
    "print (\"mean of target function =\", p)\n",
    "p = p - M_bias_gt_2(XX_test[i_test],GG_test[i_test], ZZ_test[i_test])\n",
    "print (p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "i_test = 5\n",
    "time_1 = timeit.default_timer()\n",
    "p = local_weighted_estimator(XX_test[i_test])\n",
    "print (\"mean of target function =\", p)\n",
    "p = p - Algo1.M_bias(np.array([[1]], dtype=np.int16), XX_test[i_test],GG_test[i_test], ZZ_test[i_test], h, degrees_2,Betas_2,100)\n",
    "print (p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
