{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.polynomial as P\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import Algo2\n",
    "import Algo1\n",
    "import ULA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from joblib import Parallel, delayed\n",
    "import ZVnbrosse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Algo2' from '/Users/sergosamsonoff/Research/VR-MCMC/Code/Algo2.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(Algo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_grad(x):\n",
    "    a = 1 / np.sqrt(2)\n",
    "    return x-a+2*a/(1 + np.exp(2* (x * a)))\n",
    "\n",
    "def f(x):\n",
    "    a = 1 / np.sqrt(2)\n",
    "    return 1/2 * (x-a)**2 - np.log(1 + np.exp(-2 * x * a))\n",
    "\n",
    "def set_func(x):\n",
    "    #function of interest to compute averages\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximation results: use $Q_{l-p}$ to approximate family of $Q_{l,p}$ relying on approximate stationarity of the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate samples from mixture of normals\n",
    "N_burn = 10000\n",
    "N_train = 1000\n",
    "gamma = 0.1\n",
    "N_traj_train = 1\n",
    "X_train = np.zeros((N_traj_train,N_train),dtype = float)\n",
    "\n",
    "for j in range(N_traj_train):\n",
    "    np.random.seed(42+j)\n",
    "    x0 = np.random.randn()\n",
    "    x_cur = x0\n",
    "    #burn-in\n",
    "    for i in range(N_burn):\n",
    "        x_cur = x_cur - gamma*f_grad(x_cur) + np.sqrt(2*gamma)*np.random.randn()\n",
    "    #training sample\n",
    "    for i in range(N_train):\n",
    "        X_train[j,i] = x_cur\n",
    "        x_cur = x_cur - gamma*f_grad(x_cur) + np.sqrt(2*gamma)*np.random.randn()\n",
    "X_last = X_train[0,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree\n",
    "max_deg = 5\n",
    "#lag order\n",
    "lag = 20\n",
    "#polynomial coefficients\n",
    "coefs_poly = np.zeros((lag,max_deg+1),dtype = float)\n",
    "\n",
    "for i in range(lag):\n",
    "    y = np.array([])\n",
    "    x = np.array([])\n",
    "    for j in range(N_traj_train):\n",
    "        y_cur = set_func(X_train[j,i+1:])\n",
    "        y = np.concatenate([y,y_cur])\n",
    "        x_cur = X_train[j,:-(i+1)]\n",
    "        x = np.concatenate([x,x_cur])\n",
    "    res = np.polynomial.polynomial.polyfit(x,y,max_deg)\n",
    "    coefs_poly[i,:] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000e+00 0.0000e+00 3.0000e+00 0.0000e+00 1.5000e+01 0.0000e+00\n",
      " 1.0500e+02 0.0000e+00 9.4500e+02 0.0000e+00 1.0395e+04]\n"
     ]
    }
   ],
   "source": [
    "sp.special.factorial2(21, exact=False)\n",
    "moments_stand_norm = np.zeros(2*max_deg+1,dtype = float)\n",
    "for i in range(len(moments_stand_norm)):\n",
    "    moments_stand_norm[i] = sp.special.factorial2(i+1, exact=False)\n",
    "#eliminate odd\n",
    "moments_stand_norm[1::2] = 0\n",
    "print(moments_stand_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_burn = 10000\n",
    "N_test = 1000 #size of test part\n",
    "N_min = 100 #minimal number of observations to compute \\pi_N\n",
    "gamma = 0.1\n",
    "X_test = np.zeros(N_test,dtype = float)\n",
    "Noise = np.zeros_like(X_test)\n",
    "N_traj = 10\n",
    "\n",
    "test_stat_vanilla = np.zeros((N_traj,N_test),dtype = float)\n",
    "test_stat_vr = np.zeros((N_traj,N_test),dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n",
      "100 observations proceeded\n"
     ]
    }
   ],
   "source": [
    "for ind in range(N_traj):\n",
    "    np.random.seed(1453 + ind)\n",
    "    #x0 = np.random.randn()\n",
    "    #x_cur = x0\n",
    "    #burn-in\n",
    "    #for i in range(N_burn):\n",
    "        #x_cur = x_cur - gamma*f_grad(x_cur) + np.sqrt(2*gamma)*np.random.randn()\n",
    "    #training sample\n",
    "    x_cur = X_last\n",
    "    for i in range(N_test):\n",
    "        Noise[i] = np.random.randn()\n",
    "        x_cur = x_cur - gamma*f_grad(x_cur) + np.sqrt(2*gamma)*Noise[i]\n",
    "        X_test[i] = x_cur\n",
    "    #compute polynomials at Z_l\n",
    "    poly_vals = np.zeros((max_deg+1,N_test),dtype = float)\n",
    "    for k in range(max_deg+1):\n",
    "        c = np.zeros(max_deg+1)\n",
    "        c[k] = 1\n",
    "        poly_vals[k,:] = P.hermite_e.hermeval(Noise,c)/np.sqrt((np.sqrt(2*np.pi)*sp.special.factorial(k)))\n",
    "    f_vals_vanilla = set_func(X_test)\n",
    "    cvfs = np.zeros_like(f_vals_vanilla)\n",
    "    for i in range(100,len(cvfs)):\n",
    "        #start computing a_{p-l} coefficients\n",
    "        num_poly = min(lag,i)\n",
    "        a_vals = np.zeros((num_poly,max_deg+1),dtype = float)\n",
    "        for npol in range(num_poly):#for a fixed lag Q function\n",
    "            #compute \\hat{a} with fixed lag\n",
    "            x = X_test[i-2-npol]\n",
    "            a_cur = np.zeros(max_deg+1,dtype=float)\n",
    "            for m in range(len(coefs_poly[0])):\n",
    "                poly_vspom = np.zeros(max_deg+1,dtype=float)\n",
    "                for u in range(m+1):\n",
    "                    poly_vspom[u] = ((x-gamma*f_grad(x))**(m-u))*((np.sqrt(2*gamma))**u)*sp.special.binom(m,u)\n",
    "                a_cur = P.polynomial.polyadd(a_cur,coefs_poly[npol,m]*poly_vspom) \n",
    "            for k in range(max_deg+1):\n",
    "                c = np.zeros(max_deg+1)\n",
    "                c[k] = 1\n",
    "                herm_coef = P.hermite_e.herme2poly(c)\n",
    "                #normalize now\n",
    "                herm_coef = herm_coef / np.sqrt((np.sqrt(2*np.pi)*sp.special.factorial(k)))\n",
    "                integr_coefs = P.polynomial.polymul(herm_coef,a_cur)\n",
    "                a_vals[npol,k] = np.dot(integr_coefs,moments_stand_norm[:len(integr_coefs)])\n",
    "            #OK, now I have coefficients of the polynomial, and I need to integrate it w.r.t. Gaussian measure\n",
    "        cvfs[i] = np.sum(a_vals*(poly_vals[:,i-num_poly:i].T))\n",
    "        #cvfs[i] = np.sum(np.mean(a_vals,axis = 0))\n",
    "        if (i%100 == 0):\n",
    "            print(\"100 observations proceeded\")\n",
    "        #save results\n",
    "        test_stat_vanilla[ind,i] = np.mean(f_vals_vanilla[:i])\n",
    "        test_stat_vr[ind,i] = test_stat_vanilla[ind,i] - cvfs[i]/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.65598289 1.65251426 1.65070595 1.64613828 1.64753606 1.6505027\n",
      " 1.64651145 1.64322347 1.63886391 1.63502119 1.63851211 1.64360281\n",
      " 1.6439386  1.64064989 1.63716636 1.63117952 1.62828156 1.62490718\n",
      " 1.62469658 1.61864709 1.60419456 1.5871959  1.57185665 1.55539246\n",
      " 1.54393829 1.53544292 1.53244896 1.52654861 1.52145883 1.51384827\n",
      " 1.49535273 1.47608481 1.45641101 1.43627216 1.41745355 1.40003507\n",
      " 1.38670446 1.37396639 1.36231121 1.3504072  1.3417304  1.33473354\n",
      " 1.32979215 1.32298894 1.31708715 1.31147882 1.30482002 1.30096168\n",
      " 1.29606769 1.29254181 1.28712562 1.28064792 1.27826199 1.27788385\n",
      " 1.27819465 1.28281468 1.28724118 1.28903972 1.29258912 1.29462017\n",
      " 1.29494391 1.28955863 1.2845964  1.27558831 1.27417531 1.2695974\n",
      " 1.25847945 1.24697947 1.2396776  1.23384999 1.22777313 1.21893815\n",
      " 1.20913485 1.19893316 1.18608582 1.17028454 1.1511339  1.12974125\n",
      " 1.10555627 1.07949931 1.05539153 1.03462058 1.01396495 0.99593445\n",
      " 0.98046308 0.96963644 0.95802327 0.9448823  0.93385085 0.92485349\n",
      " 0.91529131 0.90556325 0.89568736 0.88305269 0.87067852 0.86008063\n",
      " 0.85345884 0.84839512 0.8464712  0.84563409 0.84726756 0.85197443\n",
      " 0.85693444 0.85979866 0.86452231 0.86826646 0.86990401 0.87045591\n",
      " 0.87216075 0.87326107 0.87678336 0.87440435 0.87351847 0.87242776\n",
      " 0.87477886 0.87875864 0.87977671 0.88158985 0.88207627 0.88673881\n",
      " 0.88908121 0.89244433 0.89547224 0.89785667 0.89982627 0.9015059\n",
      " 0.90458065 0.90822927 0.91016032 0.91398855 0.91592281 0.92051513\n",
      " 0.9246027  0.92979083 0.932488   0.9373088  0.93940872 0.94161774\n",
      " 0.94497248 0.94652599 0.94752443 0.94679247 0.94660891 0.94841459\n",
      " 0.94730571 0.94991751 0.95134249 0.95398544 0.95338001 0.95203335\n",
      " 0.95067348 0.95070004 0.95123796 0.95484871 0.96033381 0.9648188\n",
      " 0.96763271 0.96984801 0.97224204 0.97613128 0.97906404 0.98073575\n",
      " 0.98150282 0.98150304 0.9807909  0.97673546 0.97116873 0.96669492\n",
      " 0.96187008 0.95604224 0.94969852 0.94229901 0.9366431  0.93026948\n",
      " 0.92505576 0.91948303 0.91530838 0.91435089 0.91208485 0.91048125\n",
      " 0.90762518 0.90610209 0.90063952 0.89723627 0.89405498 0.89028404\n",
      " 0.88453144 0.87933039 0.87357675 0.86739895 0.86200162 0.85629105\n",
      " 0.85202764 0.8507488  0.84948667 0.8484248  0.8484126  0.84850601\n",
      " 0.84613181 0.84357063 0.8429037  0.84436002 0.8472808  0.85107708\n",
      " 0.85399785 0.85537475 0.85518927 0.85453006 0.85485341 0.85644892\n",
      " 0.85793722 0.85981616 0.85977582 0.86053507 0.86510025 0.86997939\n",
      " 0.87478722 0.87861413 0.88033026 0.88297509 0.88589746 0.89085958\n",
      " 0.89492152 0.90000436 0.90317875 0.90634051 0.90970498 0.91316929\n",
      " 0.91863152 0.92319801 0.92708375 0.92950737 0.93022373 0.9328936\n",
      " 0.93429343 0.93525151 0.93447249 0.93499423 0.93259253 0.92861637\n",
      " 0.92591384 0.92116532 0.91406404 0.90812986 0.9002572  0.89263846\n",
      " 0.88337874 0.87546183 0.86691446 0.85999603 0.85206829 0.84388422\n",
      " 0.83576989 0.82771553 0.82039676 0.81181542 0.8013019  0.79210825\n",
      " 0.78392061 0.77549352 0.76694611 0.75949589 0.75196894 0.7457116\n",
      " 0.73953352 0.73493047 0.73158551 0.72934783 0.72773051 0.72574726\n",
      " 0.72356052 0.72245545 0.72071339 0.71914776 0.71578707 0.71219213\n",
      " 0.70761208 0.70235605 0.69617314 0.69155918 0.68645725 0.68128664\n",
      " 0.67652419 0.67215709 0.6668955  0.66209649 0.65768127 0.65336621\n",
      " 0.6500732  0.64729089 0.64431373 0.64003811 0.63559646 0.63226738\n",
      " 0.62641528 0.62078863 0.61329308 0.60506947 0.5953824  0.58461985\n",
      " 0.57608773 0.56680021 0.55873605 0.55122921 0.54486429 0.53733119\n",
      " 0.53133134 0.52494591 0.51902572 0.51495608 0.51054271 0.50650694\n",
      " 0.50185196 0.49778436 0.493008   0.48914626 0.48627731 0.48343102\n",
      " 0.47944453 0.47350526 0.46821288 0.46198602 0.45568852 0.44983997\n",
      " 0.44572548 0.44128636 0.43722389 0.43147443 0.42632306 0.42164785\n",
      " 0.41768692 0.41275226 0.40875537 0.40350793 0.3993058  0.39385799\n",
      " 0.3889517  0.38370521 0.37817939 0.37275595 0.36711068 0.36230684\n",
      " 0.35783813 0.35418683 0.35250265 0.35112932 0.34977072 0.34811633\n",
      " 0.34673034 0.3461314  0.34529199 0.34336656 0.34168425 0.34081295\n",
      " 0.34133278 0.34053653 0.33871174 0.33709313 0.33473599 0.33235527\n",
      " 0.3303992  0.32794986 0.32579112 0.32335904 0.31998699 0.31740741\n",
      " 0.31446628 0.30999265 0.3046617  0.29736061 0.29157853 0.28573637\n",
      " 0.28014815 0.274757   0.27067324 0.26687144 0.26319147 0.26005395\n",
      " 0.25643928 0.25227327 0.24822575 0.24325679 0.23924819 0.23628345\n",
      " 0.23216822 0.22644172 0.21868966 0.2113544  0.20623166 0.20118226\n",
      " 0.19701297 0.19320029 0.1880761  0.18201484 0.17713215 0.17271806\n",
      " 0.1682405  0.16506758 0.16261033 0.16052507 0.16015726 0.15969708\n",
      " 0.16050748 0.16116758 0.1610553  0.16276719 0.16377438 0.1640743\n",
      " 0.16362608 0.16315065 0.16262748 0.16142526 0.15978455 0.15776728\n",
      " 0.15532891 0.15423314 0.15249037 0.15166229 0.15119288 0.15059344\n",
      " 0.14985841 0.1489673  0.14750235 0.14412595 0.14134888 0.13807061\n",
      " 0.13533815 0.13271008 0.12947471 0.12696855 0.12313718 0.11955521\n",
      " 0.11748323 0.11648431 0.11658329 0.11633182 0.11668914 0.1180905\n",
      " 0.12015191 0.12227046 0.12384504 0.12639523 0.1309214  0.13519922\n",
      " 0.1383746  0.14139209 0.14466613 0.14712971 0.14868453 0.15074509\n",
      " 0.15303566 0.15622288 0.15876623 0.16048384 0.16258832 0.16571888\n",
      " 0.16936505 0.17265915 0.1751595  0.17631091 0.1791069  0.1818621\n",
      " 0.18352851 0.18445994 0.18475472 0.18466142 0.18465937 0.18355632\n",
      " 0.18378703 0.18466514 0.18504085 0.18516801 0.18542993 0.18615643\n",
      " 0.18867099 0.19055032 0.19209788 0.19405878 0.19591648 0.19681939\n",
      " 0.1976472  0.19866522 0.20001438 0.20158475 0.20307273 0.2038421\n",
      " 0.20378676 0.20357016 0.20169863 0.19877618 0.19533792 0.19290402\n",
      " 0.19122852 0.18976254 0.18970916 0.19010887 0.1914103  0.19292254\n",
      " 0.19426103 0.19476508 0.19576514 0.19624017 0.19643127 0.19558172\n",
      " 0.19426647 0.19344287 0.19329046 0.19253062 0.19210648 0.19183942\n",
      " 0.19298619 0.19447484 0.19598951 0.19704993 0.19786991 0.19832628\n",
      " 0.1992374  0.19966461 0.19967751 0.19956806 0.19823519 0.19598156\n",
      " 0.19435177 0.19398433 0.19286433 0.19229974 0.19187632 0.19195168\n",
      " 0.1933114  0.19414365 0.19471498 0.19463747 0.19586351 0.19698779\n",
      " 0.19840869 0.19893663 0.19969934 0.19967675 0.20073605 0.20071652\n",
      " 0.20112242 0.20265765 0.20379162 0.20463833 0.20612286 0.20869491\n",
      " 0.21152835 0.21299121 0.21573523 0.21796501 0.22084265 0.22387689\n",
      " 0.22627561 0.22899202 0.2315069  0.23415142 0.23605582 0.23782607\n",
      " 0.23958841 0.24184923 0.24322792 0.24444784 0.24554944 0.24697782\n",
      " 0.2493919  0.25241938 0.25456905 0.25681626 0.25817003 0.25961334\n",
      " 0.26072954 0.26263351 0.26460987 0.26656127 0.26782634 0.2684786\n",
      " 0.2691427  0.2697848  0.27123651 0.27216294 0.27317924 0.27248769\n",
      " 0.27241754 0.27163175 0.2716953  0.27118765 0.27114009 0.27147333\n",
      " 0.27214276 0.27277021 0.2734885  0.27488077 0.27667015 0.27771031\n",
      " 0.27877304 0.28036642 0.28124983 0.2821079  0.28231531 0.28249794\n",
      " 0.28297791 0.28378965 0.28572274 0.28835141 0.29124405 0.29478888\n",
      " 0.2977053  0.30173053 0.30462571 0.30783261 0.31038727 0.31265464\n",
      " 0.31563586 0.31789488 0.32019802 0.32118291 0.32310626 0.32532641\n",
      " 0.32728753 0.32954217 0.33140651 0.33314723 0.33488546 0.33613982\n",
      " 0.3373602  0.33791583 0.33795057 0.33824815 0.33762231 0.33695085\n",
      " 0.33669234 0.33536031 0.33470675 0.33350808 0.33329489 0.33271624\n",
      " 0.33353252 0.33527017 0.33653258 0.33767791 0.33930926 0.34060544\n",
      " 0.3431537  0.34600327 0.34872689 0.35210578 0.35444231 0.35641319\n",
      " 0.35841096 0.35877954 0.35983918 0.36173714 0.36302501 0.36348194\n",
      " 0.36380167 0.36499139 0.36530729 0.36642842 0.36695903 0.36701114\n",
      " 0.36818798 0.3690749  0.37070734 0.37307743 0.3747278  0.37675593\n",
      " 0.37881639 0.38038541 0.38180476 0.38307651 0.38428915 0.38627301\n",
      " 0.38831263 0.39018495 0.39202681 0.39376982 0.3950337  0.39733203\n",
      " 0.39927626 0.40140295 0.40221767 0.40242386 0.40269751 0.40354185\n",
      " 0.40408095 0.4045175  0.40554672 0.40664085 0.40837809 0.41056393\n",
      " 0.41287655 0.41566648 0.41746857 0.419876   0.42171445 0.42365218\n",
      " 0.42543848 0.42673396 0.42816082 0.4298269  0.43238449 0.43444855\n",
      " 0.4367708  0.43828903 0.43975789 0.44121556 0.44265037 0.44405061\n",
      " 0.4447631  0.44606523 0.44721928 0.44801214 0.44946394 0.45030195\n",
      " 0.45244868 0.45465105 0.45665293 0.45863233 0.46093175 0.46274978\n",
      " 0.46458696 0.46643866 0.46833016 0.46896361 0.46992807 0.4708631\n",
      " 0.47132822 0.4721826  0.47304951 0.47409729 0.47474603 0.47581821\n",
      " 0.47652098 0.4764225  0.47593983 0.47629875 0.47634406 0.47595293\n",
      " 0.47549716 0.47543169 0.47532727 0.47626614 0.47647283 0.47726997\n",
      " 0.47742279 0.47773168 0.4780617  0.47832879 0.47903672 0.47948539\n",
      " 0.47999818 0.48048602 0.48116054 0.48124844 0.48198145 0.48208035\n",
      " 0.48248092 0.48206226 0.48165817 0.48135471 0.48102045 0.4801026\n",
      " 0.47882787 0.47753936 0.47598699 0.47334006 0.47075403 0.46819577\n",
      " 0.46611465 0.46411418 0.46187198 0.45836891 0.45574906 0.45254731\n",
      " 0.44995145 0.44755215 0.44560858 0.44435933 0.44225415 0.44079937\n",
      " 0.43998598 0.43868312 0.4373672  0.43587378 0.43349009 0.43164298\n",
      " 0.42902931 0.4275443  0.42568309 0.42427667 0.4237011  0.42346019\n",
      " 0.42450006 0.42515207 0.42611655 0.42738651 0.42855869 0.43000809\n",
      " 0.43073449 0.43167356 0.43277589 0.43290552 0.43308969 0.43427634\n",
      " 0.43510214 0.43560767 0.43578332 0.43535296 0.43454219 0.43407522\n",
      " 0.43358066 0.43305174 0.43305965 0.43302151 0.43326653 0.43353971\n",
      " 0.43379295 0.43404328 0.43456989 0.43501353 0.43491086 0.43561962\n",
      " 0.43545082 0.43556919 0.43651478 0.4372861  0.43785289 0.43849548\n",
      " 0.4393342  0.44010087 0.44078502 0.44115149 0.44138835 0.4420519\n",
      " 0.44187254 0.44137059 0.44053125 0.43949248 0.4382788  0.43654761\n",
      " 0.43466401 0.43245673 0.43145439 0.43069462 0.43003479 0.43008627\n",
      " 0.43018844 0.42999915 0.42990072 0.43072728 0.43088302 0.43076766\n",
      " 0.43120778 0.43198662 0.43291329 0.43291828 0.43291525 0.43223629\n",
      " 0.4318088  0.43055524 0.42950406 0.42884106 0.42833903 0.42852169\n",
      " 0.42864669 0.42849837 0.42880747 0.429042   0.42887015 0.428628\n",
      " 0.42804333 0.42748575 0.42634115 0.42514433 0.42438301 0.42380791\n",
      " 0.42337698 0.42364333 0.42370046 0.42326375 0.42234629 0.42154157\n",
      " 0.42070533 0.42029444 0.41923396 0.41803225 0.41715735 0.41680449\n",
      " 0.41619045 0.4158875  0.41539435 0.41484786 0.41430353 0.41394834\n",
      " 0.41412389 0.41420092 0.41446869 0.41421378 0.41427361 0.41382232]\n",
      "[1.60377615 1.60351272 1.60048462 1.59196869 1.58890427 1.59223983\n",
      " 1.58085548 1.58162404 1.5843221  1.58989773 1.59457095 1.59191706\n",
      " 1.59772404 1.59661081 1.58010921 1.57433204 1.57612903 1.56822943\n",
      " 1.59422222 1.59024261 1.57579795 1.55476236 1.54475684 1.53768913\n",
      " 1.52667251 1.52090288 1.5201389  1.51211365 1.49316033 1.48439906\n",
      " 1.49779617 1.48492407 1.46360591 1.44239713 1.42597035 1.44384494\n",
      " 1.43488662 1.4203629  1.39461416 1.38148093 1.38505446 1.37983856\n",
      " 1.37310372 1.3473677  1.34010102 1.33038179 1.32254228 1.32255073\n",
      " 1.32096786 1.31339292 1.28744076 1.2803382  1.27801484 1.27781241\n",
      " 1.27468821 1.2782436  1.28420638 1.28286098 1.28231086 1.28307217\n",
      " 1.28509948 1.28132075 1.27757083 1.26796561 1.26138827 1.25440057\n",
      " 1.24673709 1.23410216 1.22426149 1.22089027 1.2075117  1.19766169\n",
      " 1.19467184 1.19019572 1.18277262 1.17320007 1.16240356 1.13944428\n",
      " 1.12792364 1.12806683 1.13428493 1.1240283  1.1200889  1.0861431\n",
      " 1.0568207  1.0421013  1.00993135 1.00810373 1.0019826  0.99408865\n",
      " 0.97549542 0.9569385  0.9424983  0.93166974 0.9154839  0.9028693\n",
      " 0.89698872 0.87643154 0.86745185 0.86224921 0.86324896 0.86406712\n",
      " 0.86216846 0.85810958 0.86273014 0.87222152 0.87191863 0.86921627\n",
      " 0.86748283 0.86280691 0.86363635 0.86623246 0.86926035 0.86150159\n",
      " 0.86292885 0.86007485 0.86282889 0.86194349 0.86207157 0.86734669\n",
      " 0.86792469 0.88404248 0.88339839 0.88132843 0.88716448 0.88317933\n",
      " 0.88662542 0.88609112 0.88835982 0.88614748 0.88955022 0.89545476\n",
      " 0.89819395 0.89654578 0.90696448 0.91258498 0.91343441 0.91392841\n",
      " 0.91778238 0.9349188  0.93607284 0.93466128 0.93333438 0.9338773\n",
      " 0.93202585 0.93347919 0.93490321 0.93427252 0.93198116 0.93282168\n",
      " 0.93247622 0.93650851 0.93878039 0.94141519 0.94330626 0.94893219\n",
      " 0.9529807  0.95451413 0.95475667 0.95352344 0.95371429 0.95401116\n",
      " 0.9526634  0.95551944 0.95631598 0.96344305 0.95839667 0.95916128\n",
      " 0.9523191  0.94848173 0.94371139 0.93849635 0.93527574 0.92866064\n",
      " 0.92466039 0.92206286 0.91849603 0.9180236  0.9161729  0.91574819\n",
      " 0.91262264 0.90868644 0.90488415 0.90315191 0.90638932 0.8971174\n",
      " 0.8933415  0.88628892 0.88039566 0.87296052 0.86682468 0.86131132\n",
      " 0.86113713 0.8586439  0.86142399 0.85322863 0.85345929 0.85708861\n",
      " 0.84997193 0.8459967  0.84949833 0.84899512 0.84766697 0.85165158\n",
      " 0.8523946  0.85241502 0.85454085 0.84724397 0.84545729 0.84740698\n",
      " 0.84864688 0.84415613 0.84399769 0.85280165 0.85600268 0.85770485\n",
      " 0.85975742 0.85907897 0.85979069 0.86104751 0.865935   0.87447844\n",
      " 0.88056097 0.88635715 0.88692586 0.89722037 0.88948071 0.89186534\n",
      " 0.89732537 0.89700345 0.89629948 0.90211511 0.89681719 0.89846499\n",
      " 0.91940628 0.9210682  0.91826855 0.91905802 0.91758119 0.91352797\n",
      " 0.91386355 0.91041944 0.90503501 0.9000888  0.89127027 0.88819657\n",
      " 0.88243309 0.88059144 0.87223983 0.87173049 0.87364811 0.87006144\n",
      " 0.86945946 0.86467225 0.86284107 0.85802501 0.84861946 0.84511908\n",
      " 0.82433466 0.81860018 0.81109296 0.80050239 0.78142134 0.77661858\n",
      " 0.76248224 0.75766543 0.75267686 0.74777534 0.7450948  0.74149108\n",
      " 0.73666085 0.73205615 0.72823414 0.72644545 0.72439014 0.72350808\n",
      " 0.71270775 0.7073095  0.70166923 0.69694357 0.69152352 0.68595054\n",
      " 0.68115534 0.67604931 0.67187347 0.66726634 0.66422735 0.65988795\n",
      " 0.65709525 0.65481454 0.65121954 0.64698773 0.6421988  0.64016128\n",
      " 0.63456228 0.63083253 0.6264911  0.61958365 0.61145162 0.60130103\n",
      " 0.5928622  0.58477479 0.57650397 0.57175476 0.5683234  0.56843433\n",
      " 0.56846437 0.56788733 0.56724664 0.56492538 0.55922798 0.55263906\n",
      " 0.54842667 0.54145769 0.52255221 0.51879299 0.50938855 0.50214964\n",
      " 0.4936093  0.49726965 0.48822473 0.47628653 0.4719719  0.46602922\n",
      " 0.46195454 0.45288592 0.44876364 0.44491523 0.43980721 0.43678979\n",
      " 0.43463068 0.43048309 0.42452139 0.42474131 0.4189288  0.41491288\n",
      " 0.41152125 0.40998667 0.40188066 0.38802356 0.3840811  0.3779405\n",
      " 0.3737299  0.37101423 0.36921103 0.36725002 0.36427731 0.35907204\n",
      " 0.35579924 0.35348584 0.35134253 0.34921283 0.34797728 0.34586315\n",
      " 0.34509198 0.34421959 0.34290379 0.34078535 0.33854033 0.3333491\n",
      " 0.33204137 0.33012141 0.32696015 0.32500097 0.32185654 0.31990549\n",
      " 0.31796031 0.31517202 0.31075576 0.30685768 0.3041117  0.2979029\n",
      " 0.29585028 0.29134045 0.28633741 0.2795824  0.2757775  0.27557807\n",
      " 0.27720021 0.27737254 0.27265551 0.26634829 0.25962703 0.25760362\n",
      " 0.2573348  0.2550179  0.25215099 0.25376906 0.2472146  0.22459204\n",
      " 0.21648271 0.21101516 0.21050867 0.20962852 0.20363433 0.20427733\n",
      " 0.20406331 0.20369976 0.19687725 0.20367812 0.20070013 0.19346704\n",
      " 0.18833476 0.18291218 0.17657369 0.17758426 0.17208478 0.16842295\n",
      " 0.17045357 0.16829288 0.16729099 0.16456913 0.16149779 0.15622753\n",
      " 0.15360485 0.15303186 0.1521327  0.1527079  0.15207592 0.15008131\n",
      " 0.14918414 0.14795693 0.14711693 0.14563604 0.1457157  0.14225471\n",
      " 0.13973355 0.13748781 0.13500072 0.13320412 0.13091699 0.12697539\n",
      " 0.12553429 0.12875574 0.12737558 0.12531894 0.12604895 0.13091696\n",
      " 0.12975417 0.13135024 0.13130424 0.13115737 0.13351804 0.13729996\n",
      " 0.13886882 0.13986538 0.14050411 0.13988442 0.13819102 0.14064759\n",
      " 0.14211984 0.14454154 0.14854518 0.15004948 0.15253988 0.15394755\n",
      " 0.15521207 0.15942566 0.16163454 0.16032527 0.16253494 0.16344958\n",
      " 0.17758877 0.17832544 0.17833947 0.17810414 0.1781135  0.17746754\n",
      " 0.17645193 0.17943542 0.17860707 0.18044467 0.18042655 0.18267386\n",
      " 0.18251077 0.18530339 0.18767729 0.18584332 0.18674249 0.18754128\n",
      " 0.19465841 0.19411869 0.19567297 0.19731276 0.1976845  0.19745638\n",
      " 0.19644649 0.19784578 0.19780906 0.19508901 0.19340494 0.19270008\n",
      " 0.1938889  0.189313   0.19141356 0.19103251 0.19141778 0.19428842\n",
      " 0.19767538 0.20182347 0.20077387 0.19937304 0.19860703 0.19625848\n",
      " 0.19510131 0.19497183 0.19736613 0.19568765 0.19303913 0.19204754\n",
      " 0.19258717 0.19321348 0.19282829 0.19209468 0.19602771 0.19658539\n",
      " 0.19849695 0.19919848 0.19836176 0.19848098 0.1971582  0.19519108\n",
      " 0.1960644  0.19387268 0.19372678 0.19309132 0.19217762 0.19109855\n",
      " 0.19156263 0.19014568 0.19515136 0.19651439 0.19713236 0.19763812\n",
      " 0.19817407 0.19839198 0.198909   0.19857159 0.19849892 0.19898712\n",
      " 0.19886071 0.19952155 0.19834943 0.20022735 0.20192138 0.20294501\n",
      " 0.20469394 0.20409123 0.21054089 0.21134807 0.21154099 0.21334539\n",
      " 0.21991341 0.22039961 0.22180367 0.22322667 0.2233902  0.22465431\n",
      " 0.2285416  0.23072269 0.23061585 0.23507079 0.23534739 0.23675372\n",
      " 0.23990533 0.24524233 0.24420206 0.24722576 0.25374065 0.25504859\n",
      " 0.25729924 0.25940802 0.26098132 0.26353966 0.26420171 0.26429233\n",
      " 0.26463695 0.26570675 0.26626487 0.2674769  0.26938881 0.26840234\n",
      " 0.26798583 0.26779769 0.26968351 0.26995487 0.26996558 0.27019084\n",
      " 0.27143317 0.27160602 0.27219262 0.27602509 0.27819378 0.27834336\n",
      " 0.27884651 0.27906903 0.27895904 0.27966571 0.28000162 0.28127926\n",
      " 0.2831919  0.2818135  0.28348855 0.28488947 0.28852937 0.29174661\n",
      " 0.2944796  0.2972823  0.29931881 0.30083054 0.30231674 0.30610136\n",
      " 0.30893909 0.31164714 0.31299907 0.31387308 0.31458402 0.31655838\n",
      " 0.31746068 0.31643222 0.31652223 0.31730221 0.32210744 0.32453231\n",
      " 0.32576058 0.32882011 0.3290362  0.33343753 0.33271437 0.33309445\n",
      " 0.33369313 0.33304958 0.33452076 0.33399881 0.3336443  0.33033296\n",
      " 0.33186932 0.33385875 0.33491715 0.33646617 0.33839883 0.34000378\n",
      " 0.3419842  0.34415231 0.34463322 0.34677759 0.34742161 0.34678675\n",
      " 0.34753437 0.34958003 0.35140662 0.35126025 0.35154832 0.35224529\n",
      " 0.35106355 0.35307122 0.3548509  0.35743063 0.35842354 0.35970829\n",
      " 0.35924121 0.35920009 0.36589024 0.3671204  0.36765058 0.37144462\n",
      " 0.37086604 0.37153105 0.37231414 0.3733092  0.37483709 0.37818154\n",
      " 0.37932274 0.38045666 0.38024155 0.38414477 0.38495582 0.38799485\n",
      " 0.38980881 0.39075311 0.39557908 0.39519307 0.39791913 0.39994566\n",
      " 0.40027328 0.40089295 0.40225929 0.40254695 0.40441428 0.40569037\n",
      " 0.40646831 0.41256239 0.4133696  0.41383892 0.41450376 0.41442344\n",
      " 0.41609731 0.4221084  0.42284514 0.42463492 0.42711681 0.42855812\n",
      " 0.43001785 0.43190443 0.43243149 0.43333739 0.43497376 0.43595475\n",
      " 0.43840479 0.44052548 0.44161194 0.44325312 0.44441635 0.44626855\n",
      " 0.44787614 0.44958807 0.45063039 0.452393   0.45381383 0.45373003\n",
      " 0.45990326 0.46165352 0.46332836 0.46398523 0.4643731  0.46537623\n",
      " 0.46735157 0.46570761 0.46605237 0.46697638 0.46750473 0.46733996\n",
      " 0.46911919 0.46911758 0.47444154 0.47465678 0.47468967 0.47390197\n",
      " 0.47485919 0.47434046 0.47521077 0.47528392 0.47435557 0.47542539\n",
      " 0.47564756 0.4756319  0.47582904 0.47606456 0.47628246 0.47704345\n",
      " 0.47758123 0.47770834 0.47755388 0.47769829 0.47849777 0.47941558\n",
      " 0.47970897 0.4794741  0.47854537 0.47864906 0.47849255 0.47954495\n",
      " 0.47832089 0.47767936 0.47554483 0.47379942 0.4715868  0.46970403\n",
      " 0.46764125 0.46692056 0.46593276 0.46459309 0.4626763  0.46024044\n",
      " 0.45921071 0.4573249  0.45617404 0.45304349 0.45657644 0.45518364\n",
      " 0.45327582 0.45294295 0.45353395 0.45096514 0.44712304 0.44268293\n",
      " 0.44098716 0.44033022 0.44044252 0.43876998 0.43809438 0.43237246\n",
      " 0.43305772 0.43209215 0.43214976 0.43199029 0.43061326 0.43125631\n",
      " 0.43143032 0.43124234 0.43050299 0.42938307 0.4273902  0.42900705\n",
      " 0.42972652 0.42765528 0.42787544 0.4295585  0.42743269 0.42776367\n",
      " 0.42951894 0.42860254 0.43141273 0.43140208 0.43222946 0.43301222\n",
      " 0.43304509 0.43339818 0.43311616 0.43305818 0.43261195 0.43253425\n",
      " 0.43161226 0.43486953 0.43606365 0.43703757 0.43743901 0.43779313\n",
      " 0.437889   0.43862994 0.43896715 0.43917871 0.44025328 0.43994943\n",
      " 0.43961434 0.43878245 0.43780689 0.43695986 0.43738898 0.43676581\n",
      " 0.4360293  0.43460369 0.43175334 0.42986066 0.4297107  0.42994885\n",
      " 0.43032189 0.43103055 0.43065728 0.43134633 0.43157876 0.43141588\n",
      " 0.43129583 0.432275   0.43196538 0.43290076 0.43166518 0.43012397\n",
      " 0.42962871 0.42847776 0.4283897  0.42722344 0.42752006 0.42810564\n",
      " 0.42756655 0.42868627 0.42785872 0.42886818 0.42758506 0.42948725\n",
      " 0.42856837 0.42782283 0.42729114 0.42644029 0.42708684 0.42536447\n",
      " 0.42547837 0.42482506 0.42428364 0.42327836 0.42184989 0.42147137\n",
      " 0.42071959 0.42069921 0.41998199 0.41897738 0.41846052 0.41793161\n",
      " 0.41752257 0.41727341 0.41654846 0.4159435  0.41487872 0.41426289\n",
      " 0.41489072 0.41457294 0.41431184 0.41474621 0.41489405 0.4142766 ]\n"
     ]
    }
   ],
   "source": [
    "print(test_stat_vanilla[1,N_min:])\n",
    "print(test_stat_vr[1,N_min:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2455638  0.24665074 0.24830918 0.2487423  0.25096556 0.25349112\n",
      " 0.25439903 0.25448522 0.25389267 0.25285693]\n",
      "[0.21349191 0.21511742 0.21723522 0.21189183 0.21257877 0.21091325\n",
      " 0.20844613 0.21417611 0.21349367 0.21897067]\n",
      "0.9815929289766613\n"
     ]
    }
   ],
   "source": [
    "vars_vanilla = np.var(test_stat_vanilla,axis = 0)\n",
    "vars_adj = np.var(test_stat_vr,axis = 0)\n",
    "print(vars_vanilla[N_min:N_min+10])\n",
    "print(vars_adj[N_min:N_min+10])\n",
    "print(np.mean(vars_adj[N_min:]/vars_vanilla[N_min:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
