{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.polynomial as P\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import Algo2\n",
    "import Algo1\n",
    "import ULA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from joblib import Parallel, delayed\n",
    "import ZVnbrosse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(Algo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_grad(x):\n",
    "    a = 1 / np.sqrt(2)\n",
    "    return x-a+2*a/(1 + np.exp(2* (x * a)))\n",
    "\n",
    "def f(x):\n",
    "    a = 1 / np.sqrt(2)\n",
    "    return 1/2 * (x-a)**2 - np.log(1 + np.exp(-2 * x * a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximation results: use $Q_{l-p}$ to approximate family of $Q_{l,p}$ relying on approximate stationarity of the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate samples from mixture of normals\n",
    "N_burn = 10000\n",
    "N_train = 2000\n",
    "gamma = 0.1\n",
    "X_train = np.zeros(N_train,dtype = float)\n",
    "\n",
    "np.random.seed(42)\n",
    "x0 = np.random.randn()\n",
    "x_cur = x0\n",
    "#burn-in\n",
    "for i in range(N_burn):\n",
    "    x_cur = x_cur - gamma*f_grad(x_cur) + np.sqrt(2*gamma)*np.random.randn()\n",
    "#training sample\n",
    "for i in range(N_train):\n",
    "    X_train[i] = x_cur\n",
    "    x_cur = x_cur - gamma*f_grad(x_cur) + np.sqrt(2*gamma)*np.random.randn()\n",
    "X_last = X_train[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree\n",
    "max_deg = 5\n",
    "#lag order\n",
    "lag = 30\n",
    "#polynomial coefficients\n",
    "coefs_hermite = np.zeros((lag,max_deg+1),dtype = float)\n",
    "\n",
    "for i in range(lag):\n",
    "    y = X_train[i+1:]\n",
    "    x = X_train[:-(i+1)]\n",
    "    res = np.polynomial.hermite_e.hermefit(x,y,max_deg)\n",
    "    coefs_hermite[i,:] = res\n",
    "#transform into usual polynomials\n",
    "coefs_poly = np.zeros_like(coefs_hermite)\n",
    "for i in range(lag):\n",
    "    coefs_poly[i,:] = np.polynomial.hermite_e.herme2poly(coefs_hermite[i,:])\n",
    "print(coefs_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.special.factorial2(21, exact=False)\n",
    "moments_stand_norm = np.zeros(2*max_deg+1,dtype = float)\n",
    "for i in range(len(moments_stand_norm)):\n",
    "    moments_stand_norm[i] = sp.special.factorial2(i+1, exact=False)\n",
    "#eliminate odd\n",
    "moments_stand_norm[1::2] = 0\n",
    "print(moments_stand_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_burn = 10000\n",
    "N_test = 1000 #size of test part\n",
    "N_min = 100 #minimal number of observations to compute \\pi_N\n",
    "gamma = 0.1\n",
    "X_test = np.zeros(N_test,dtype = float)\n",
    "Noise = np.zeros_like(X_test)\n",
    "N_traj = 10\n",
    "\n",
    "test_stat_vanilla = np.zeros((N_traj,N_test),dtype = float)\n",
    "test_stat_vr = np.zeros((N_traj,N_test),dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in range(N_traj):\n",
    "    np.random.seed(1453 + ind)\n",
    "    #x0 = np.random.randn()\n",
    "    #x_cur = x0\n",
    "    #burn-in\n",
    "    #for i in range(N_burn):\n",
    "        #x_cur = x_cur - gamma*f_grad(x_cur) + np.sqrt(2*gamma)*np.random.randn()\n",
    "    #training sample\n",
    "    x_cur = X_last\n",
    "    for i in range(N_test):\n",
    "        Noise[i] = np.random.randn()\n",
    "        x_cur = x_cur - gamma*f_grad(x_cur) + np.sqrt(2*gamma)*Noise[i]\n",
    "        X_test[i] = x_cur\n",
    "    #compute polynomials at Z_l\n",
    "    poly_vals = np.zeros((max_deg+1,N_test),dtype = float)\n",
    "    for k in range(max_deg+1):\n",
    "        c = np.zeros(max_deg+1)\n",
    "        c[k] = 1\n",
    "        poly_vals[k,:] = P.hermite_e.hermeval(Noise,c)/np.sqrt((np.sqrt(2*np.pi)*sp.special.factorial(k)))\n",
    "    f_vals_vanilla = X_test**2\n",
    "    cvfs = np.zeros_like(f_vals_vanilla)\n",
    "    for i in range(100,len(cvfs)):\n",
    "        x = X_test[i]\n",
    "        #start computing a_{p-l} coefficients\n",
    "        num_poly = min(lag,i)\n",
    "        a_vals = np.zeros((num_poly,max_deg+1),dtype = float)\n",
    "        for npol in range(num_poly):#for a fixed lag Q function\n",
    "            #compute \\hat{a} with fixed lag\n",
    "            a_cur = np.zeros(max_deg+1,dtype=float)\n",
    "            for m in range(len(coefs_poly[0])):\n",
    "                poly_vspom = np.zeros(max_deg+1,dtype=float)\n",
    "                for u in range(m+1):\n",
    "                    poly_vspom[u] = ((x-gamma*f_grad(x))**(m-u))*((np.sqrt(2*gamma))**u)*sp.special.binom(m,u)\n",
    "                a_cur = P.polynomial.polyadd(a_cur,coefs_poly[npol,m]*poly_vspom) \n",
    "            for k in range(max_deg+1):\n",
    "                c = np.zeros(max_deg+1)\n",
    "                c[k] = 1\n",
    "                herm_coef = P.hermite_e.herme2poly(c)\n",
    "                #normalize now\n",
    "                herm_coef = herm_coef / np.sqrt((np.sqrt(2*np.pi)*sp.special.factorial(k)))\n",
    "                integr_coefs = P.polynomial.polymul(herm_coef,a_cur)\n",
    "                a_vals[npol,k] = np.dot(integr_coefs,moments_stand_norm[:len(integr_coefs)])\n",
    "            #OK, now I have coefficients of the polynomial, and I need to integrate it w.r.t. Gaussian measure\n",
    "        cvfs[i] = np.sum(a_vals*(poly_vals[:,i-num_poly:i].T))\n",
    "        #cvfs[i] = np.sum(np.mean(a_vals,axis = 0))\n",
    "        if (i%100 == 0):\n",
    "            print(\"100 observations proceeded\")\n",
    "        #save results\n",
    "        test_stat_vanilla[ind,i] = np.mean(f_vals_vanilla[:i])\n",
    "        test_stat_vr[ind,i] = test_stat_vanilla[ind,i] - cvfs[i]/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_stat_vanilla[0,:])\n",
    "print(test_stat_vr[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_vanilla = np.var(test_stat_vanilla,axis = 0)\n",
    "vars_adj = np.var(test_stat_vr,axis = 0)\n",
    "print(vars_vanilla[N_min:N_min+10])\n",
    "print(vars_adj[N_min:N_min+10])\n",
    "print(np.mean(vars_adj[N_min:]/vars_vanilla[N_min:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
