{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.polynomial as P\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import Algo2\n",
    "import Algo1\n",
    "import ULA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from joblib import Parallel, delayed\n",
    "import ZVnbrosse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(Algo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_grad(x):\n",
    "    a = 0.0\n",
    "    return x-a+2*a/(1 + np.exp(2* (x * a)))\n",
    "\n",
    "def f(x):\n",
    "    a = 1 / np.sqrt(2)\n",
    "    return 1/2 * (x-a)**2 - np.log(1 + np.exp(-2 * x * a))\n",
    "\n",
    "def set_func(x):\n",
    "    #function of interest to compute averages\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for normal distribution\n",
    "a = 0.0\n",
    "sigma = 1.0\n",
    "\n",
    "def f_grad(x):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximation results: use $Q_{l-p}$ to approximate family of $Q_{l,p}$ relying on approximate stationarity of the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate samples from mixture of normals\n",
    "N_burn = 10000\n",
    "N_train = 10000\n",
    "gamma = 0.2\n",
    "N_traj_train = 1\n",
    "X_train = np.zeros((N_traj_train,N_train),dtype = float)\n",
    "\n",
    "for j in range(N_traj_train):\n",
    "    np.random.seed(42+j)\n",
    "    x0 = np.random.randn()\n",
    "    x_cur = x0\n",
    "    #burn-in\n",
    "    for i in range(N_burn):\n",
    "        x_cur = x_cur - gamma*f_grad(x_cur) + np.sqrt(2*gamma)*np.random.randn()\n",
    "    #training sample\n",
    "    for i in range(N_train):\n",
    "        X_train[j,i] = x_cur\n",
    "        x_cur = x_cur - gamma*f_grad(x_cur) + np.sqrt(2*gamma)*np.random.randn()\n",
    "X_last = X_train[0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(X_train[0,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree\n",
    "max_deg = 2\n",
    "#lag order\n",
    "lag = 10\n",
    "#polynomial coefficients\n",
    "coefs_poly = np.zeros((lag,max_deg+1),dtype = float)\n",
    "\n",
    "for i in range(lag):\n",
    "    y = set_func(X_train[0,(i+1):])\n",
    "    x = X_train[0,:-(i+1)]\n",
    "    res = P.polynomial.polyfit(x,y,max_deg)\n",
    "    coefs_poly[i,:] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coefs_poly[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_lag = 5\n",
    "N_pts = 100\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.title(\"Testing regression model\",fontsize=20)\n",
    "plt.plot(X_train[0,cur_lag:N_pts],color='r',label='true function')\n",
    "plt.plot(P.polynomial.polyval(X_train[0,:N_pts-cur_lag],coefs_poly[cur_lag-1,:]),color='g',label = 'approximation')\n",
    "plt.legend(loc = 'lower right',fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.special.factorial2(21, exact=False)\n",
    "moments_stand_norm = np.zeros(2*max_deg+1,dtype = float)\n",
    "for i in range(len(moments_stand_norm)):\n",
    "    moments_stand_norm[i] = sp.special.factorial2(i+1, exact=False)\n",
    "#eliminate odd\n",
    "moments_stand_norm[1::2] = 0\n",
    "print(moments_stand_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_burn = 10000\n",
    "N_test = 2000 #size of test part\n",
    "N_min = 1000 #minimal number of observations to compute \\pi_N\n",
    "gamma = 0.2\n",
    "X_test = np.zeros(N_test,dtype = float)\n",
    "Noise = np.zeros_like(X_test)\n",
    "N_traj = 10\n",
    "\n",
    "test_stat_vanilla = np.zeros((N_traj,N_test),dtype = float)\n",
    "test_stat_vr = np.zeros((N_traj,N_test),dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in range(N_traj):\n",
    "    np.random.seed(1453 + ind)\n",
    "    #x0 = np.random.randn()\n",
    "    #x_cur = x0\n",
    "    #burn-in\n",
    "    #for i in range(N_burn):\n",
    "        #x_cur = x_cur - gamma*f_grad(x_cur) + np.sqrt(2*gamma)*np.random.randn()\n",
    "    #training sample\n",
    "    x_cur = X_last\n",
    "    for i in range(N_test):\n",
    "        Noise[i] = np.random.randn()\n",
    "        x_cur = x_cur - gamma*f_grad(x_cur) + np.sqrt(2*gamma)*Noise[i]\n",
    "        X_test[i] = x_cur\n",
    "    #compute polynomials at Z_l\n",
    "    poly_vals = np.zeros((max_deg+1,N_test),dtype = float)\n",
    "    for k in range(max_deg+1):\n",
    "        c = np.zeros(max_deg+1)\n",
    "        c[k] = 1\n",
    "        poly_vals[k,:] = P.hermite_e.hermeval(Noise,c)/np.sqrt((np.sqrt(2*np.pi)*sp.special.factorial(k)))\n",
    "    f_vals_vanilla = set_func(X_test)\n",
    "    cvfs = np.zeros_like(f_vals_vanilla)\n",
    "    for i in range(100,len(cvfs)):\n",
    "        #start computing a_{p-l} coefficients\n",
    "        num_poly = min(lag,i)\n",
    "        a_vals = np.zeros((num_poly,max_deg+1),dtype = float)\n",
    "        for npol in range(num_poly):#for a fixed lag Q function\n",
    "            #compute \\hat{a} with fixed lag\n",
    "            x = X_test[i-2-npol]#should be -2 here?\n",
    "            a_cur = np.zeros(max_deg+1,dtype=float)\n",
    "            for m in range(len(coefs_poly[0])):\n",
    "                poly_vspom = np.zeros(max_deg+1,dtype=float)\n",
    "                for u in range(m+1):\n",
    "                    poly_vspom[u] = ((x-gamma*f_grad(x))**(m-u))*((np.sqrt(2*gamma))**u)*sp.special.binom(m,u)\n",
    "                a_cur = P.polynomial.polyadd(a_cur,coefs_poly[npol,m]*poly_vspom) \n",
    "            for k in range(max_deg+1):\n",
    "                c = np.zeros(max_deg+1)\n",
    "                c[k] = 1\n",
    "                herm_coef = P.hermite_e.herme2poly(c)\n",
    "                #normalize now\n",
    "                herm_coef = herm_coef / np.sqrt((np.sqrt(2*np.pi)*sp.special.factorial(k)))\n",
    "                integr_coefs = P.polynomial.polymul(herm_coef,a_cur)\n",
    "                #Note that a_vals are stored in reversed order\n",
    "                a_vals[-(npol+1),k] = np.dot(integr_coefs,moments_stand_norm[:len(integr_coefs)])\n",
    "            #OK, now I have coefficients of the polynomial, and I need to integrate it w.r.t. Gaussian measure\n",
    "        cvfs[i] = np.sum(a_vals*(poly_vals[:,i-num_poly+1:i+1].T))\n",
    "        #cvfs[i] = np.sum(np.mean(a_vals,axis = 0))\n",
    "        if (i%100 == 0):\n",
    "            print(\"100 observations proceeded\")\n",
    "        #save results\n",
    "        test_stat_vanilla[ind,i] = np.mean(f_vals_vanilla[:i])\n",
    "        test_stat_vr[ind,i] = test_stat_vanilla[ind,i] - cvfs[i]/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_stat_vanilla[1,N_min:N_min+100])\n",
    "print(test_stat_vr[1,N_min:N_min+100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_vanilla = np.var(test_stat_vanilla,axis = 0)\n",
    "vars_adj = np.var(test_stat_vr,axis = 0)\n",
    "print(vars_vanilla[N_min:N_min+10])\n",
    "print(vars_adj[N_min:N_min+10])\n",
    "print(np.mean(vars_adj[N_min:]/vars_vanilla[N_min:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
